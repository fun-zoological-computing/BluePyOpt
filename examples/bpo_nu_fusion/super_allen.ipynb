{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'inject_and_plot_model30' from 'neuronunit.optimisation.optimization_management' (/home/user/safe2/neuronunit/neuronunit/optimisation/optimization_management.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a60149e94fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmake_allen_tests_from_id\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization_management\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtc_to_rheo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minject_and_plot_model30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck_bin_vm30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck_bin_vm15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'inject_and_plot_model30' from 'neuronunit.optimisation.optimization_management' (/home/user/safe2/neuronunit/neuronunit/optimisation/optimization_management.py)"
     ]
    }
   ],
   "source": [
    "import faulthandler; faulthandler.enable()\n",
    "\n",
    "import pickle\n",
    "import make_allen_tests_from_id# import *\n",
    "\n",
    "from make_allen_tests_from_id import *\n",
    "from neuronunit.optimisation.optimization_management import dtc_to_rheo, inject_and_plot_model30,check_bin_vm30,check_bin_vm15\n",
    "\n",
    "\n",
    "import efel\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "list(efel.getFeatureNames());\n",
    "from utils import dask_map_function\n",
    "\n",
    "import bluepyopt as bpop\n",
    "import bluepyopt.ephys as ephys\n",
    "import pickle\n",
    "from sciunit.scores import ZScore, RatioScore\n",
    "from sciunit import TestSuite\n",
    "from sciunit.scores.collections import ScoreArray\n",
    "import sciunit\n",
    "import numpy as np\n",
    "from neuronunit.optimisation.optimization_management import dtc_to_rheo, switch_logic,active_values\n",
    "from neuronunit.tests.base import AMPL, DELAY, DURATION\n",
    "\n",
    "import quantities as pq\n",
    "PASSIVE_DURATION = 500.0*pq.ms\n",
    "PASSIVE_DELAY = 200.0*pq.ms\n",
    "import matplotlib.pyplot as plt\n",
    "from bluepyopt.ephys.models import ReducedCellModel\n",
    "import numpy\n",
    "from neuronunit.optimisation.optimization_management import test_all_objective_test\n",
    "from neuronunit.optimisation.optimization_management import check_binary_match, three_step_protocol,inject_and_plot_passive_model\n",
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from make_allen_tests import AllenTest\n",
    "\n",
    "from sciunit.scores import ZScore\n",
    "from collections.abc import Iterable\n",
    "\n",
    "from bluepyopt.parameters import Parameter\n",
    "from utils import dask_map_function\n",
    "\n",
    "\n",
    "#tests = pickle.load(open('allen_NU_tests.p','rb'))\n",
    "#names = [t.name for t in tests[3].tests ]\n",
    "#names;\n",
    "\n",
    "\n",
    "simple_yes_list = ['mean_AP_amplitude','mean_frequenc','min_AHP_values','min_voltage_between_spikes','minimum_voltage ','all_ISI_values','ISI_log_slope','mean_frequency','adaptation_index2','first_isi','ISI_CV','median_isi','AHP_depth_abs','sag_ratio2','ohmic_input_resistance','sag_ratio2','peak_voltage','voltage_base','Spikecount','ohmic_input_resistance_vb_ssse']\n",
    "\n",
    "#simple_yes_list = ['mean_frequency','ISI_log_slope','adaptation_index2','AHP_depth_abs','sag_ratio2','ohmic_input_resistance','sag_ratio2','peak_voltage','voltage_base','Spikecount','ohmic_input_resistance_vb_ssse']\n",
    "\n",
    "\n",
    "names = [t.observation for t in tests[3].tests if \"Spike\" in t.name]\n",
    "names\n",
    "specimen_id = tests[3].name\n",
    "\n",
    "# initialize the cacher\n",
    "try:\n",
    "    with open(str(specimen_id)+'later_allen_NU_tests.p','rb') as f:\n",
    "        suite = pickle.load(f) \n",
    "\n",
    "except:\n",
    "    specimen_id = tests[3].name\n",
    "    sweep_numbers,data_set,sweeps = make_allen_tests_from_id.allen_id_to_sweeps(specimen_id)\n",
    "    vm15,vm30,rheobase,currents,vmrh = make_allen_tests_from_id.get_model_parts(data_set,sweep_numbers,specimen_id,simple_yes_list)\n",
    "    suite,specimen_id = make_allen_tests_from_id.make_suite_from_static_models(vm15,vm30,rheobase,currents,vmrh,specimen_id,simple_yes_list)\n",
    "    with open(str(specimen_id)+'later_allen_NU_tests.p','wb') as f:\n",
    "        pickle.dump(suite,f) \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "specific_filter_list = ['mean_AP_amplitude_1.5x','mean_frequency_1.5x','min_AHP_indices_1.5x','min_AHP_values_1.5x','min_voltage_between_spikes_1.5x','minimum_voltage_1.5x ','ISI_log_slope_1.5x','mean_frequency_1.5x','adaptation_index2_1.5x','first_isi_1.5x','ISI_CV_1.5x','median_isi_1.5x','AHP_depth_abs_1.5x','sag_ratio2_1.5x','ohmic_input_resistance_1.5x','sag_ratio2_1.5x','peak_voltage_1.5x','voltage_base_1.5x','Spikecount_1.5x']#,'Spikecount_3.0x']\n",
    "\n",
    "        \n",
    "target = StaticModel(vm=suite.traces['vmrh']) #DataTC(backend=\"ADEXP\")\n",
    "target.vm30 = suite.traces['vm30'] \n",
    "target.vm15 = suite.traces['vm15'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_bin_vm30(target,target)\n",
    "\n",
    "check_bin_vm15(target,target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_tests = suite.tests;\n",
    "for t in nu_tests:\n",
    "    print(t.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nu_tests = suite.tests;\n",
    "\n",
    "\n",
    "attrs = {k:np.mean(v) for k,v in MODEL_PARAMS[\"ADEXP\"].items()}\n",
    "dtc = DataTC(backend=\"ADEXP\",attrs=attrs)\n",
    "for t in nu_tests:\n",
    "    if t.name == 'Spikecount_1.5x':\n",
    "        spk_count = float(t.observation['mean'])\n",
    "        print(spk_count,'spike_count')\n",
    "        break\n",
    "observation_range={}\n",
    "observation_range['value'] = spk_count\n",
    "scs = SpikeCountSearch(observation_range)\n",
    "model = dtc.dtc_to_model()\n",
    "target_current = scs.generate_prediction(model)\n",
    "\n",
    "ALLEN_DELAY = 1000.0*qt.s\n",
    "ALLEN_DURATION = 2000.0*qt.s\n",
    "\n",
    "\n",
    "uc = {'amplitude':target_current['value'],'duration':ALLEN_DURATION,'delay':ALLEN_DELAY}\n",
    "model = dtc.dtc_to_model()\n",
    "\n",
    "model.inject_square_current(uc)\n",
    "print(model.get_spike_count(),'spikes')\n",
    "\n",
    "\n",
    "tg = target_current['value']\n",
    "MODEL_PARAMS[\"ADEXP\"]#[\"current_inj\"] = [tg-0.25*tg,tg+0.25*tg]\n",
    "\n",
    "simple_cell = ephys.models.ReducedCellModel(\n",
    "        name='simple_cell',\n",
    "        params=MODEL_PARAMS[\"ADEXP\"],backend=\"ADEXP\")  \n",
    "simple_cell.backend = \"ADEXP\"\n",
    "simple_cell.allen = None\n",
    "simple_cell.allen = True\n",
    "\n",
    "\n",
    "model = simple_cell\n",
    "model.params = {k:np.mean(v) for k,v in model.params.items() }\n",
    "\n",
    "features = None\n",
    "allen = True\n",
    "\n",
    "\n",
    "yes_list = specific_filter_list \n",
    "class NUFeatureAllenMultiSpike(object):\n",
    "    def __init__(self,test,model,cnt,target,check_list,spike_obs,print_stuff=False):\n",
    "        self.test = test\n",
    "        self.model = model\n",
    "        self.check_list = check_list\n",
    "        self.spike_obs = spike_obs\n",
    "        self.cnt = cnt\n",
    "        self.target = target\n",
    "        self.print_stuff = print_stuff\n",
    "    def calculate_score(self,responses):\n",
    "        \n",
    "        if not 'features' in responses.keys():# or not 'model' in responses.keys():\n",
    "            return 1000.0\n",
    "        features = responses['features']\n",
    "        if type(features) is type(None):\n",
    "            return 1000.0\n",
    "\n",
    "        check_list = self.check_list\n",
    "    \n",
    "        self.test.score_type = RatioScore\n",
    "\n",
    "\n",
    "        feature_name = self.test.name\n",
    "        delta1 = np.abs(features['Spikecount_1.5x']-np.mean(self.spike_obs[0]['mean']))\n",
    "        if feature_name not in features.keys():\n",
    "            return 1000.0+(delta1)\n",
    "        \n",
    "        if features[feature_name] is None:\n",
    "            return 1000.0+(delta1)\n",
    "            \n",
    "        if type(features[self.test.name]) is type(Iterable):\n",
    "            features[self.test.name] = np.mean(features[self.test.name])\n",
    "        self.test.observation['std'] = np.abs(np.mean(self.test.observation['mean']))\n",
    "        self.test.observation['mean'] = np.mean(self.test.observation['mean'])   \n",
    "        self.test.set_prediction(np.mean(features[self.test.name]))\n",
    "\n",
    "        #if 'Spikecount_3.0x'==feature_name or \n",
    "        if 'Spikecount_1.5x'==feature_name:\n",
    "            delta = np.abs(features[self.test.name]-np.mean(self.test.observation['mean']))\n",
    "            if np.nan==delta or delta==np.inf:\n",
    "                delta = 1000.0\n",
    "\n",
    "            \n",
    "            return delta\n",
    "        else:\n",
    "\n",
    "\n",
    "            if feature_name in check_list:\n",
    "                if features[feature_name] is None:\n",
    "                    print('gets here')\n",
    "                    return 1000.0+(delta1)\n",
    "                self.test.score_type = ZScore\n",
    "                score_gene = self.test.feature_judge()\n",
    "                if score_gene is not None:\n",
    "                    if score_gene.log_norm_score is not None:\n",
    "                        delta = np.abs(float(score_gene.log_norm_score))\n",
    "                    else:\n",
    "                        if score_gene.raw is not None:\n",
    "                            delta = np.abs(float(score_gene.raw))\n",
    "                        else:\n",
    "                            delta = None\n",
    "\n",
    "                else:\n",
    "                    delta = None\n",
    "\n",
    "                if delta is None:\n",
    "                    delta = np.abs(features[self.test.name]-np.mean(self.test.observation['mean']))\n",
    "\n",
    "\n",
    "                if np.nan==delta or delta==np.inf:\n",
    "                    delta = np.abs(features[self.test.name]-np.mean(self.test.observation['mean']))\n",
    "                if np.nan==delta or delta==np.inf:\n",
    "                    delta = 1000.0\n",
    "                return delta#+delta2\n",
    "            else:\n",
    "                return 0.0\n",
    "   \n",
    "objectives = []\n",
    "spike_obs = []\n",
    "for tt in nu_tests:\n",
    "    if 'Spikecount_1.5x' == tt.name:\n",
    "        spike_obs.append(tt.observation)\n",
    "spike_obs = sorted(spike_obs, key=lambda k: k['mean'],reverse=True)\n",
    "\n",
    "#check_list[\"RheobaseTest\"] = target.rheobase['value']\n",
    "for cnt,tt in enumerate(nu_tests):\n",
    "    feature_name = '%s' % (tt.name)\n",
    "    if feature_name in specific_filter_list:\n",
    "        #if 'Spikecount_3.0x' == tt.name or \n",
    "        if 'Spikecount_1.5x' == tt.name:\n",
    "            ft = NUFeatureAllenMultiSpike(tt,model,cnt,yes_list,yes_list,spike_obs)\n",
    "            objective = ephys.objectives.SingletonObjective(\n",
    "                feature_name,\n",
    "                ft)\n",
    "            objectives.append(objective)\n",
    "\n",
    "       \n",
    "score_calc = ephys.objectivescalculators.ObjectivesCalculator(objectives) \n",
    "      \n",
    "lop={}\n",
    "\n",
    "for k,v in MODEL_PARAMS[\"ADEXP\"].items():\n",
    "    p = Parameter(name=k,bounds=v,frozen=False)\n",
    "    lop[k] = p\n",
    "\n",
    "simple_cell.params = lop\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sweep_protocols = []\n",
    "for protocol_name, amplitude in [('step1', 0.05)]:\n",
    "\n",
    "    protocol = ephys.protocols.SweepProtocol(protocol_name, [None], [None])\n",
    "    sweep_protocols.append(protocol)\n",
    "twostep_protocol = ephys.protocols.SequenceProtocol('twostep', protocols=sweep_protocols)\n",
    "\n",
    "simple_cell.params_by_names(MODEL_PARAMS[\"ADEXP\"].keys())\n",
    "simple_cell.params;\n",
    "\n",
    "MODEL_PARAMS[\"ADEXP\"]\n",
    "cell_evaluator = ephys.evaluators.CellEvaluator(\n",
    "        cell_model=simple_cell,\n",
    "        param_names=MODEL_PARAMS[\"ADEXP\"].keys(),\n",
    "        fitness_protocols={twostep_protocol.name: twostep_protocol},\n",
    "        fitness_calculator=score_calc,\n",
    "        sim='euler')\n",
    "\n",
    "simple_cell.params_by_names(MODEL_PARAMS[\"ADEXP\"].keys())\n",
    "simple_cell.params;\n",
    "simple_cell.seeded_current = target_current['value']\n",
    "simple_cell.spk_count = spk_count\n",
    "\n",
    "\n",
    "\n",
    "no_list = pickle.load(open(\"too_rippled_b.p\",\"rb\"))\n",
    "\n",
    "\n",
    "objectives2 = []\n",
    "for cnt,tt in enumerate(nu_tests):\n",
    "    feature_name = '%s' % (tt.name)\n",
    "    if (feature_name not in no_list) and (feature_name in specific_filter_list):\n",
    "        if feature_name != \"time_constant_1.5x\" and feature_name != \"RheobaseTest\":\n",
    "            ft = NUFeatureAllenMultiSpike(tt,model,cnt,yes_list,yes_list,spike_obs,print_stuff=True)\n",
    "            objective = ephys.objectives.SingletonObjective(\n",
    "                feature_name,\n",
    "                ft)\n",
    "            objectives2.append(objective)\n",
    "objectives2\n",
    "score_calc2 = ephys.objectivescalculators.ObjectivesCalculator(objectives2) \n",
    "objectives2\n",
    "\n",
    "\n",
    "\n",
    "MODEL_PARAMS[\"ADEXP\"]\n",
    "cell_evaluator2 = ephys.evaluators.CellEvaluator(\n",
    "        cell_model=simple_cell,\n",
    "        param_names=list(MODEL_PARAMS[\"ADEXP\"].keys()),\n",
    "        fitness_protocols={twostep_protocol.name: twostep_protocol},\n",
    "        fitness_calculator=score_calc2,\n",
    "        sim='euler')\n",
    "simple_cell.params_by_names(MODEL_PARAMS[\"ADEXP\"].keys())\n",
    "\n",
    "simple_cell.params;\n",
    "\n",
    "\n",
    "MODEL_PARAMS[\"ADEXP\"]\n",
    "cell_evaluator2 = ephys.evaluators.CellEvaluator(\n",
    "        cell_model=simple_cell,\n",
    "        param_names=list(MODEL_PARAMS[\"ADEXP\"].keys()),\n",
    "        fitness_protocols={twostep_protocol.name: twostep_protocol},\n",
    "        fitness_calculator=score_calc2,\n",
    "        sim='euler')\n",
    "\n",
    "MU = 15\n",
    "\n",
    "optimisation = bpop.optimisations.DEAPOptimisation(\n",
    "        evaluator=cell_evaluator2,\n",
    "        offspring_size = MU,\n",
    "        map_function = map,\n",
    "        selector_name='IBEA',mutpb=0.1,cxpb=0.35)\n",
    "final_pop, hall_of_fame, logs, hist = optimisation.run(max_ngen=100)\n",
    "cp = {}\n",
    "cp['final_pop'] = final_pop\n",
    "cp['hall_of_fame'] = hall_of_fame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('allen_opt.p','rb') as f:\n",
    "    [final_pop, hall_of_fame, logs, hist] = pickle.load(f)\n",
    "    \n",
    "    \n",
    "best_ind = hall_of_fame[2]\n",
    "best_ind_dict = cell_evaluator2.param_dict(best_ind)\n",
    "model = cell_evaluator2.cell_model\n",
    "\n",
    "model.attrs = {str(k):float(v) for k,v in cell_evaluator2.param_dict(best_ind).items()}\n",
    "opt = model.model_to_dtc()\n",
    "opt.attrs = {str(k):float(v) for k,v in cell_evaluator2.param_dict(best_ind).items()}\n",
    "target = copy.copy(opt)\n",
    "target.vm15 = suite.traces['vm15'] \n",
    "check_bin_vm15(target,target)\n",
    "\n",
    "\n",
    "#target.vm30 = suite.traces['vm30']#.times \n",
    "#target.vm15 = target.vm15[0:int(len(vm)/2)]\n",
    "#target.vm30 = target.vm15\n",
    "#check_bin_vm15(target,target)\n",
    "#vm = suite.traces['vm30']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitness = cell_evaluator2.param_dict(best_ind)\n",
    "fitnesses = hall_of_fame[0].fitness.values\n",
    "fitnesses\n",
    "from sciunit.scores.collections import ScoreArray\n",
    "tests = [i.features[0].test for i in objectives2]\n",
    "scores_ = [j for j in fitnesses]\n",
    "#ScoreArray([(j,) for i,j in zip(objectives2,fitnesses)])\n",
    "\n",
    "SA = ScoreArray(tests, scores_)\n",
    "SA.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#opt.known_current = 10\n",
    "#opt.spk_count = 11\n",
    "\n",
    "#vm301,vm151,_,_,target = inject_and_plot_model30(target)\n",
    "\n",
    "#check_bin_vm30(opt,opt)\n",
    "\n",
    "\n",
    "#check_bin_vm30(target,target)\n",
    "observation_range={}\n",
    "observation_range['value'] = 11\n",
    "scs = SpikeCountSearch(observation_range)\n",
    "model = opt.dtc_to_model()\n",
    "target_current = scs.generate_prediction(model)\n",
    "opt.known_current = target_current\n",
    "opt.spk_count = spk_count\n",
    "\n",
    "vm152,_,_,opt = inject_and_plot_model30(opt,known_current=target_current)\n",
    "check_bin_vm15(opt,opt)\n",
    "check_bin_vm15(target,opt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_expVar(trace1, trace2):\n",
    "    # https://github.com/AllenInstitute/GLIF_Teeter_et_al_2018/blob/master/query_biophys/query_biophys_expVar.py\n",
    "    '''This is the fundamental calculation that is used in all different types of explained variation.  \n",
    "    At a basic level, the explained variance is calculated between two traces.  These traces can be PSTH's\n",
    "    or single spike trains that have been convolved with a kernel (in this case always a Gaussian)\n",
    "    Input:\n",
    "        trace 1 & 2:  1D numpy array containing values of the trace.  (This function requires numpy array\n",
    "                        to ensure that this is not a multidemensional list.)\n",
    "    Returns:\n",
    "        expVar:  float value of explained variance\n",
    "    '''\n",
    "    \n",
    "    var_trace1=np.var(trace1)\n",
    "    var_trace2=np.var(trace2)\n",
    "    var_trace1_minus_trace2=np.var(trace1-trace2)\n",
    "\n",
    "    if var_trace1_minus_trace2 == 0.0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return (var_trace1+var_trace2-var_trace1_minus_trace2)/(var_trace1+var_trace2)\n",
    "#basic_expVar(target.vm15, opt.vm15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_numbers = logs.select('gen')\n",
    "min_fitness = logs.select('min')\n",
    "max_fitness = logs.select('max')\n",
    "avg_fitness = logs.select('avg')\n",
    "plt.plot(gen_numbers, max_fitness, label='max fitness')\n",
    "plt.plot(gen_numbers, avg_fitness, label='avg fitness')\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
    "\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
    "plt.semilogy()\n",
    "plt.xlabel('generation #')\n",
    "plt.ylabel('score (# std)')\n",
    "plt.legend()\n",
    "plt.xlim(min(gen_numbers) - 1, max(gen_numbers) + 1) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('allen_opt.p','wb') as f:\n",
    "    pickle.dump([final_pop, hall_of_fame, logs, hist],f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
