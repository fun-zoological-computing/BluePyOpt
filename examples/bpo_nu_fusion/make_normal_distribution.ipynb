{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/lib/python3.7/site-packages/cerberus/validator.py:1609: UserWarning: No validation schema is defined for the arguments of rule 'not_zero_obs_zscore'\n",
      "  \"'%s'\" % method_name.split('_', 2)[-1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns',None)\n",
    "pd.set_option('max_rows',None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "from neuronunit.optimization.optimization_management import instance_opt\n",
    "from neuronunit.optimization.optimization_management import plot_as_normal\n",
    "from neuronunit.optimization.optimization_management import inject_and_not_plot_model, which_key\n",
    "from neuronunit.capabilities.spike_functions import get_spike_waveforms#\n",
    "from neuronunit.optimization.optimization_management import TSD\n",
    "from neuronunit.optimization.model_parameters import MODEL_PARAMS, BPO_PARAMS\n",
    "from neuronunit.optimization.optimization_management import inject_and_not_plot_model, plot_as_normal\n",
    "from neuronunit.optimization.optimization_management import inject_and_plot_model, plot_as_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428\" ><thead>    <tr>        <th class=\"index_name level0\" >name</th>        <th class=\"col_heading level0 col0\" >nan</th>        <th class=\"col_heading level0 col1\" >Hippocampus CA1 pyramidal cell</th>        <th class=\"col_heading level0 col2\" >Cerebellum Purkinje cell</th>        <th class=\"col_heading level0 col3\" >Neocortex pyramidal cell layer 5-6</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row0\" class=\"row_heading level0 row0\" >RheobaseTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row0_col1\" class=\"data row0 col1\" >189.24 pA</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row0_col2\" class=\"data row0 col2\" >680.794444444444 pA</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row0_col3\" class=\"data row0 col3\" >213.849583333333 pA</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row1\" class=\"row_heading level0 row1\" >InputResistanceTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row1_col1\" class=\"data row1 col1\" >107.080327644332 Mohm</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row1_col2\" class=\"data row1 col2\" >142.057692307692 Mohm</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row1_col3\" class=\"data row1 col3\" >120.672073643411 Mohm</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row2\" class=\"row_heading level0 row2\" >TimeConstantTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row2_col1\" class=\"data row2 col1\" >24.5021946169772 ms</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row2_col3\" class=\"data row2 col3\" >15.7342424242424 ms</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row3\" class=\"row_heading level0 row3\" >CapacitanceTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row3_col0\" class=\"data row3 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row3_col1\" class=\"data row3 col1\" >89.7960714285714 pF</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row3_col2\" class=\"data row3 col2\" >620.2725 pF</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row3_col3\" class=\"data row3 col3\" >150.584166666667 pF</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row4\" class=\"row_heading level0 row4\" >RestingPotentialTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row4_col1\" class=\"data row4 col1\" >-65.2261863636364 mV</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row4_col2\" class=\"data row4 col2\" >-61.5916666666667 mV</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row4_col3\" class=\"data row4 col3\" >-68.2481434599156 mV</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row5\" class=\"row_heading level0 row5\" >InjectedCurrentAPWidthTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row5_col0\" class=\"data row5 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row5_col1\" class=\"data row5 col1\" >1.31895278450363 ms</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row5_col2\" class=\"data row5 col2\" >0.41412962962963 ms</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row5_col3\" class=\"data row5 col3\" >1.20769387755102 ms</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row6\" class=\"row_heading level0 row6\" >InjectedCurrentAPAmplitudeTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row6_col0\" class=\"data row6 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row6_col1\" class=\"data row6 col1\" >86.364525297619 mV</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row6_col2\" class=\"data row6 col2\" >71.2308333333333 mV</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row6_col3\" class=\"data row6 col3\" >80.4351020408164 mV</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428level0_row7\" class=\"row_heading level0 row7\" >InjectedCurrentAPThresholdTest</th>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row7_col0\" class=\"data row7 col0\" >nan</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row7_col1\" class=\"data row7 col1\" >-47.5985714285714 mV</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row7_col2\" class=\"data row7 col2\" >-46.8947619047619 mV</td>\n",
       "                        <td id=\"T_584b0b06_5a09_11eb_a429_5f9803a48428row7_col3\" class=\"data row7 col3\" >-42.7357232704403 mV</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4d77b563d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cells = pickle.load(open(\"processed_multicellular_constraints.p\",\"rb\"))\n",
    "\n",
    "purk = TSD(cells['Cerebellum Purkinje cell'])#.tests\n",
    "purk_vr = purk[\"RestingPotentialTest\"].observation['mean']\n",
    "\n",
    "ncl5 = TSD(cells[\"Neocortex pyramidal cell layer 5-6\"])\n",
    "ncl5.name = str(\"Neocortex pyramidal cell layer 5-6\")\n",
    "ncl5_vr = ncl5[\"RestingPotentialTest\"].observation['mean']\n",
    "\n",
    "ca1 = TSD(cells['Hippocampus CA1 pyramidal cell'])\n",
    "ca1_vr = ca1[\"RestingPotentialTest\"].observation['mean']\n",
    "\n",
    "\n",
    "experimental_constraints= cells\n",
    "\n",
    "list_of_dicts = []\n",
    "for k,v in cells.items():\n",
    "    observations = {}\n",
    "    for k1 in ca1.keys():\n",
    "        vsd = TSD(v)\n",
    "        if k1 in vsd.keys():\n",
    "            vsd[k1].observation['mean']\n",
    "            observations[k1] = vsd[k1].observation['mean']\n",
    "            observations['name'] = k\n",
    "    list_of_dicts.append(observations)\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "df\n",
    "df = df.set_index('name').T\n",
    "\n",
    "s = df.style.background_gradient(cmap=cm)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IZHINeocortex pyramidal cell layer 5-6 IZHI\n"
     ]
    }
   ],
   "source": [
    "#try:\n",
    "#    temp = TSD(pickle.load(open(\"Neocortex pyramidal cell layer 5-6\"+\"IZHI_.p\",\"rb\")))\n",
    "#    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "#except:\n",
    "MU = 10\n",
    "NGEN = 10\n",
    "final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "    TSD(experimental_constraints[\"Neocortex pyramidal cell layer 5-6\"]),\n",
    "    BPO_PARAMS,\"Neocortex pyramidal cell layer 5-6\",\"IZHI\",\n",
    "    MU,\n",
    "    NGEN,\n",
    "    \"IBEA\",\n",
    "    use_streamlit=False)\n",
    "\n",
    "temp = final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value\n",
    "pickle.dump(temp,open(\"Neocortex pyramidal cell layer 5-6\"+\"IZHI_.p\",\"wb\"))\n",
    "chi_sqr_opt, p_value\n",
    "chi_sqr_opt, p_value\n",
    "df = pd.DataFrame([{'chi_square':chi_sqr_opt,'p_value':p_value}]).T    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.SA.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.make_pretty(opt.tests)\n",
    "opt.obs_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Izhikevich model Hippocampus CA1 pyramidal experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    temp = pickle.load(open(\"Hippocampus CA1 pyramidal cell\"+\"IZHI_.p\",\"rb\"))\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "except:\n",
    "    MU = 45\n",
    "    NGEN = 150\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "        TSD(experimental_constraints['Hippocampus CA1 pyramidal cell']),\n",
    "        MODEL_PARAMS,'Hippocampus CA1 pyramidal cell',\"IZHI\",\n",
    "        MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "    temp = final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value\n",
    "    pickle.dump(temp,open('Hippocampus CA1 pyramidal cell'+\"IZHI_.p\",\"wb\"))\n",
    "chi_sqr_opt, p_value\n",
    "chi_sqr_opt, p_value\n",
    "pd.DataFrame([{'chi_square':chi_sqr_opt,'p_value':p_value}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.make_pretty(opt.tests)\n",
    "opt.obs_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.SA\n",
    "\n",
    "out = inject_and_plot_model(opt,plotly=False)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Conductance Based model Hippocampus CA1 pyramidal experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "\n",
    "    temp = pickle.load(open(\"Hippocampus CA1 pyramidal cell\"+\"NEURONHH_.p\",\"rb\"))\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "except:\n",
    "    MU = 10\n",
    "    NGEN = 45\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "        experimental_constraints['Hippocampus CA1 pyramidal cell'],\n",
    "        MODEL_PARAMS,'Hippocampus CA1 pyramidal cell',\"NEURONHH\",\n",
    "        MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "    temp = final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value\n",
    "    pickle.dump(temp,open('Hippocampus CA1 pyramidal cell'+\"NEURONHH_.p\",\"wb\"))\n",
    "chi_sqr_opt, p_value\n",
    "pd.DataFrame([{'chi_square':chi_sqr_opt,'p_value':p_value}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqr_opt, p_value\n",
    "pd.DataFrame([{'chi_square':chi_sqr_opt,'p_value':p_value}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = inject_and_not_plot_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.SA.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.make_pretty(opt.tests)\n",
    "opt.obs_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(out.times,out.magnitude)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Exponential Model Hippocampus CA1 pyramidal Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    temp = pickle.load(open(\"Hippocampus CA1 pyramidal cell\"+\"ADEXP_.p\",\"rb\"))\n",
    "    final_pop, hall_of_fame, logs, hist, ad_opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "except:\n",
    "    MU = 25\n",
    "    NGEN = 100\n",
    "    final_pop, hall_of_fame, logs, hist, ad_opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "        experimental_constraints['Hippocampus CA1 pyramidal cell'],\n",
    "        MODEL_PARAMS,'Hippocampus CA1 pyramidal cell',\"ADEXP\",\n",
    "        MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "    temp = final_pop, hall_of_fame, logs, hist, ad_opt, obs_preds, chi_sqr_opt, p_value\n",
    "    pickle.dump(temp,open('Hippocampus CA1 pyramidal cell'+\"ADEXP_.p\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_tuple = inject_and_plot_model(ad_opt,plotly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_tuple[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqr_opt, p_value\n",
    "pd.DataFrame([{'chi_square':chi_sqr_opt,'p_value':p_value}]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.SA.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.make_pretty(opt.tests)\n",
    "opt.obs_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olfactory Mitral Cell Experiment/ Izhikevich Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(experimental_constraints['olf_mit']) is not type(list()):\n",
    "    experimental_constraints['olf_mit'] = list(experimental_constraints['olf_mit'].values())    \n",
    "try:\n",
    "    temp = pickle.load(open(\"olf_mit\"+\"IZHI_.p\",\"rb\"))\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "except:\n",
    "    MU = 40\n",
    "    NGEN = 150\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "        experimental_constraints['olf_mit'],\n",
    "        MODEL_PARAMS,'olf_mit',\"IZHI\",\n",
    "        MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "    temp = final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value\n",
    "    pickle.dump(temp,open('olf_mit'+\"IZHI_.p\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{'chi_square':chi_sqr_opt,'p_value':p_value}]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.SA.to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.make_pretty(opt.tests)\n",
    "opt.obs_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neocortex Pyramidal Experiment Conductance based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cerebellum Purkinje cell Experiment Conductance Izhikevich Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "try:\n",
    "    temp = pickle.load(open(\"Cerebellum Purkinje cell\"+\"IZHI_.p\",\"rb\"))\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "except:\n",
    "    MU = 25\n",
    "    NGEN = 200\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "        experimental_constraints['Cerebellum Purkinje cell'],\n",
    "        MODEL_PARAMS,'Cerebellum Purkinje cell',\"IZHI\",\n",
    "        MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "    temp =  final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value\n",
    "    pickle.dump(temp,open('Cerebellum Purkinje cell'+\"IZHI_.p\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "try:\n",
    "    temp = pickle.load(open(\"Neocortex pyramidal cell layer 5-6\"+\"ADEXP_.p\",\"rb\"))\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "except:\n",
    "    MU = 10\n",
    "    NGEN = 150\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "        experimental_constraints['Neocortex pyramidal cell layer 5-6'],\n",
    "        MODEL_PARAMS,'Neocortex pyramidal cell layer 5-6',\"ADEXP\",\n",
    "        MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "    temp = final_pop, hall_of_fame, logs, hist, opt, obs_preds\n",
    "    pickle.dump(temp,open('Neocortex pyramidal cell layer 5-6'+\"ADEXP_.p\",\"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp = pickle.load(open(\"Neocortex pyramidal cell layer 5-6\"+\"IZHI_.p\",\"rb\"))\n",
    "final_pop, hall_of_fame, logs, hist, opt, obs_preds = temp\n",
    "zvalues_opt = opt.SA.values\n",
    "chi_sqr_opt= np.sum(zvalues_opt**2)\n",
    "print(1-scipy.stats.chi2.cdf(chi_sqr_opt, 8))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OM = opt.dtc_to_opt_man()\n",
    "stats = OM.random_sample(opt,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#stats\n",
    "from neuronunit.optimisation.optimization_management import plot_as_normal_all, plot_as_normal\n",
    "\n",
    "plot_as_normal_all(opt,stats['best_random_model'])\n",
    "import numpy as np\n",
    "np.mean(opt.SA.values)\n",
    "opt.SA.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_random=[]\n",
    "import numpy as np\n",
    "#dir(stats['best_random_model'].SA['RheobaseTest'])\n",
    "for t in stats['best_random_model'].tests:\n",
    "    model = stats['best_random_model'].dtc_to_model()\n",
    "    score = t.judge(model)\n",
    "    z_random.append(np.abs(float(score.raw)))\n",
    "#np.mean(mean_random)\n",
    "\n",
    "#[z**2 for z in z_random]\n",
    "z_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_sqr_random = np.sum(np.array(z_random)**2)\n",
    "\n",
    "#chi_sqr_random = np.sum(zvalues_opt**2)\n",
    "print(1-scipy.stats.chi2.cdf(chi_sqr_random, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = opt.SA.to_frame()\n",
    "score_frame = frame.T\n",
    "score_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.make_pretty(opt.tests)\n",
    "opt.obs_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuronunit.optimisation.optimization_management import plot_as_normal_all, plot_as_normal\n",
    "opt.rheobase\n",
    "plot_as_normal(opt)\n",
    "plot_as_normal_all(opt,stats['best_random_model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert 1==2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS\n",
    "MU = 15\n",
    "NGEN = 80\n",
    "final_pop, hall_of_fame, logs, hist, opt, obs_preds = instance_opt(\n",
    "    experimental_constraints[\"Cerebellum Purkinje cell\"],\n",
    "    MODEL_PARAMS,\"Cerebellum Purkinje cell\",\"ADEXP\",\n",
    "    MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "opt.obs_preds.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "try:\n",
    "    temp = pickle.load(open(\"Neocortex pyramidal cell layer 5-6\"+\"NEURON_HH_.p\",\"rb\"))\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = temp\n",
    "except:\n",
    "    MU = 10\n",
    "    NGEN = 10\n",
    "    final_pop, hall_of_fame, logs, hist, opt, obs_preds, chi_sqr_opt, p_value = instance_opt(\n",
    "        experimental_constraints['Neocortex pyramidal cell layer 5-6'],\n",
    "        MODEL_PARAMS,'Neocortex pyramidal cell layer 5-6',\"NEURON_HH\",\n",
    "        MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n",
    "    temp = final_pop, hall_of_fame, logs, hist, opt, obs_preds\n",
    "    pickle.dump(temp,open('Neocortex pyramidal cell layer 5-6'+\"NEURON_HH.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OM = opt.dtc_to_opt_man()\n",
    "stats = OM.random_sample(opt,100)\n",
    "\n",
    "from neuronunit.optimisation.optimization_management import plot_as_normal_all, plot_as_normal\n",
    "opt.rheobase\n",
    "plot_as_normal(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_as_normal_all(opt,stats['best_random_model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.backend\n",
    "\n",
    "from neuronunit.optimisation.optimization_management import inject_and_plot_model, inject_and_plot_model30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm,plt,pre_model = inject_and_plot_model(opt,plotly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inject_and_plot_model30(opt)#,plotly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS\n",
    "MU = 25\n",
    "NGEN = 100\n",
    "\n",
    "final_pop, hall_of_fame, logs, hist, opt, obs_preds = instance_opt(\n",
    "    experimental_constraints[\"Hippocampus CA1 pyramidal cell\"],\n",
    "    MODEL_PARAMS,\"Hippocampus CA1 pyramidal cell\",\n",
    "    \"IZHI\",MU,NGEN,\"IBEA\",use_streamlit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pop, hall_of_fame, logs, hist, opt, obs_preds = instance_opt(\n",
    "    experimental_constraints[\"olf_mit\"],\n",
    "    MODEL_PARAMS,\"olf_mit\",\"IZHI\",\n",
    "    MU,NGEN,\"IBEA\",use_streamlit=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from deap import creator, base, tools\n",
    "import array\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=tuple(-1.0 for i in range(0,8)))\n",
    "creator.create(\"Individual\", array.array, typecode='d', fitness=creator.FitnessMin)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, creator.Individual)\n",
    "list_out = pickle.load(open('dump_neuron_olf.p','rb'))\n",
    "neuron_olf = list_out[1][0].dtc\n",
    "\n",
    "neuron_olf.SA\n",
    "neuron_olf.get_agreement()\n",
    "neuron_olf.agreement\n",
    "neuron_olf.SA\n",
    "neuron_olf.agreement    \n",
    "neuron_olf.name = 'olf_mit'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "models_hh=[]\n",
    "for f in hh_files:\n",
    "    model = pickle.load(open(f,'rb'))\n",
    "    print(f)\n",
    "    try:\n",
    "        model.name = f\n",
    "        models_hh.append(model)\n",
    "    except:\n",
    "        pass\n",
    "models_hh_r = models_hh[::-1]\n",
    "for m in models_hh_r:\n",
    "    print(m.name)\n",
    "    \n",
    "\n",
    "models_hh_r.append(neuron_olf)\n",
    "\n",
    "models_hh.append(neuron_olf)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sciunit.scores import ZScore\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "\n",
    "#dtc = neuron_olf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig,axes = plt.subplots(2,math.ceil(len(dtc.tests)/2),figsize=(20,8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#axes[0,0].plot(scores)\n",
    "axes[0,0].set_title('Optimized model position relative to data')\n",
    "\n",
    "for i,t in enumerate(dtc.tests):\n",
    "\n",
    "    t.score_type = ZScore\n",
    "    model = dtc.dtc_to_model()\n",
    "    score = t.judge(model)\n",
    "    x1 = -1.01\n",
    "    x2 = 1.0\n",
    "    sigma = 1.0\n",
    "    mu = 0\n",
    "    x = np.arange(-sigma, sigma, 0.001) # range of x in spec\n",
    "    x_all = np.arange(-sigma, sigma, 0.001) \n",
    "    y_point = norm.pdf(mu+float(score.raw),0,1)\n",
    "    y2 = norm.pdf(x_all,0,1)\n",
    "\n",
    "    y = norm.pdf(x,0,1)\n",
    "    y2 = norm.pdf(x_all,0,1)\n",
    "\n",
    "    ax = axes.flat[i]\n",
    "\n",
    "    x_point = mu+float(score.raw)\n",
    "\n",
    "    ax.scatter(x_point,y_point,c='r',s=300,marker='o')\n",
    "    name = t.name.split('Test')[0]\n",
    "\n",
    "    ax.set_title(str(name)+str(' ')+str(t.observation['mean'].units))\n",
    "    ax.plot(x_all,y2)\n",
    "    ax.set_xlim([-1.0,1.0])\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot between -10 and 10 with .001 steps.\n",
    "x_axis = np.arange(-1, 1, 0.001)\n",
    "# Mean = 0, SD = 2.\n",
    "plt.plot(x_axis, norm.pdf(x_axis,0,10))\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "from scipy.stats import norm\n",
    "\n",
    "def z_val(sig_level=0.05, two_tailed=True):\n",
    "    \"\"\"Returns the z value for a given significance level\"\"\"\n",
    "    z_dist = scs.norm()\n",
    "    if two_tailed:\n",
    "        sig_level = sig_level/2\n",
    "        area = 1 - sig_level\n",
    "    else:\n",
    "        area = 1 - sig_level\n",
    "\n",
    "    z = z_dist.ppf(area)\n",
    "\n",
    "    return z\n",
    "  \n",
    "  \n",
    "def zplot(x_point,y_point,area=0.95, two_tailed=True, align_right=False):\n",
    "    \"\"\"Plots a z distribution with common annotations\n",
    "    Example:\n",
    "        zplot(area=0.95)\n",
    "        zplot(area=0.80, two_tailed=False, align_right=True)\n",
    "    Parameters:\n",
    "        area (float): The area under the standard normal distribution curve.\n",
    "        align (str): The area under the curve can be aligned to the center\n",
    "            (default) or to the left.\n",
    "    Returns:\n",
    "        None: A plot of the normal distribution with annotations showing the\n",
    "        area under the curve and the boundaries of the area.\n",
    "    \"\"\"\n",
    "    # create plot object\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.subplots()\n",
    "    # create normal distribution\n",
    "    norm = scs.norm()\n",
    "    # create data points to plot\n",
    "    x = np.linspace(-5, 5, 1000)\n",
    "    y = norm.pdf(x)\n",
    "\n",
    "    ax.plot(x, y)\n",
    "    ax.scatter(x_point,y_point,c='r',s=300,marker='o')\n",
    "\n",
    "    # code to fill areas for two-tailed tests\n",
    "    if two_tailed:\n",
    "        left = norm.ppf(0.5 - area / 2)\n",
    "        right = norm.ppf(0.5 + area / 2)\n",
    "        ax.vlines(right, 0, norm.pdf(right), color='grey', linestyle='--')\n",
    "        ax.vlines(left, 0, norm.pdf(left), color='grey', linestyle='--')\n",
    "\n",
    "        ax.fill_between(x, 0, y, color='grey', alpha='0.25',\n",
    "                        where=(x > left) & (x < right))\n",
    "        plt.xlabel('z')\n",
    "        plt.ylabel('PDF')\n",
    "        plt.text(left, norm.pdf(left), \"z = {0:.3f}\".format(left), fontsize=12,\n",
    "                 rotation=90, va=\"bottom\", ha=\"right\")\n",
    "        plt.text(right, norm.pdf(right), \"z = {0:.3f}\".format(right),\n",
    "                 fontsize=12, rotation=90, va=\"bottom\", ha=\"left\")\n",
    "    # for one-tailed tests\n",
    "    else:\n",
    "        # align the area to the right\n",
    "        if align_right:\n",
    "            left = norm.ppf(1-area)\n",
    "            ax.vlines(left, 0, norm.pdf(left), color='grey', linestyle='--')\n",
    "            ax.fill_between(x, 0, y, color='grey', alpha='0.25',\n",
    "                            where=x > left)\n",
    "            plt.text(left, norm.pdf(left), \"z = {0:.3f}\".format(left),\n",
    "                     fontsize=12, rotation=90, va=\"bottom\", ha=\"right\")\n",
    "        # align the area to the left\n",
    "        else:\n",
    "            right = norm.ppf(area)\n",
    "            ax.vlines(right, 0, norm.pdf(right), color='grey', linestyle='--')\n",
    "            ax.fill_between(x, 0, y, color='grey', alpha='0.25',\n",
    "                            where=x < right)\n",
    "            plt.text(right, norm.pdf(right), \"z = {0:.3f}\".format(right),\n",
    "                     fontsize=12, rotation=90, va=\"bottom\", ha=\"left\")\n",
    "\n",
    "    # annotate the shaded area\n",
    "    plt.text(0, 0.1, \"shaded area = {0:.3f}\".format(area), fontsize=12,\n",
    "             ha='center')\n",
    "    # axis labels\n",
    "    plt.xlabel('z')\n",
    "    plt.ylabel('PDF')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i,t in enumerate(dtc.tests):\n",
    "\n",
    "    t.score_type = ZScore\n",
    "    model = dtc.dtc_to_model()\n",
    "    score = t.judge(model)\n",
    "    x1 = -1.01\n",
    "    x2 = 1.0\n",
    "    sigma = 1.0\n",
    "    mu = 0\n",
    "    x = np.arange(-sigma, sigma, 0.001) # range of x in spec\n",
    "    x_all = np.arange(-sigma, sigma, 0.001) \n",
    "    y_point = norm.pdf(mu+float(score.raw),0,1)\n",
    "    y2 = norm.pdf(x_all,0,1)\n",
    "\n",
    "    y = norm.pdf(x,0,1)\n",
    "    y2 = norm.pdf(x_all,0,1)\n",
    "\n",
    "    ax = axes.flat[i]\n",
    "\n",
    "    x_point = mu+float(score.raw)\n",
    "    zplot(x_point,y_point)\n",
    "    break\n",
    "    \n",
    "    ax.scatter(x_point,y_point,c='r',s=300,marker='o')\n",
    "    name = t.name.split('Test')[0]\n",
    "\n",
    "    ax.set_title(str(name)+str(' ')+str(t.observation['mean'].units))\n",
    "    ax.plot(x_all,y2)\n",
    "    ax.set_xlim([-1.0,1.0])\n",
    "    \n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,t in enumerate(dtc.tests):\n",
    "    print(t.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zplot(x_point,y_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "list_of_dics = []    \n",
    "for m in models_hh_r:\n",
    "    name = str(m.name)\n",
    "    try:\n",
    "        name = name.split('dump_')[1]\n",
    "    except:\n",
    "        name = name\n",
    "    m.SA['name'] = name\n",
    "    temp = {str(k):v for k,v in m.SA.items()}\n",
    "    list_of_dics.append(temp)\n",
    "df_scores = pd.DataFrame(list_of_dics)\n",
    "df_scores\n",
    "df_scores = df_scores.set_index('name').T\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_izhi=[]\n",
    "for f in izhi_files:\n",
    "    model = pickle.load(open(f,'rb'))\n",
    "    model.name = f\n",
    "    #print(f)\n",
    "    models_izhi.append(model)\n",
    "    \n",
    "for m in models_izhi:\n",
    "    print(m.name)    \n",
    "    \n",
    "list_of_dics = []    \n",
    "for m in models_izhi:\n",
    "    name = str(m.name)\n",
    "    try:\n",
    "        name = name.split('dump_')[1]\n",
    "    except:\n",
    "        name = name\n",
    "    m.SA['name'] = name\n",
    "    temp = {str(k):v for k,v in m.SA.items()}\n",
    "    list_of_dics.append(temp)\n",
    "df_scores = pd.DataFrame(list_of_dics)\n",
    "df_scores\n",
    "df_scores = df_scores.set_index('name').T\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.optimization_management import check_match_front, inject_and_not_plot_model\n",
    "from neuronunit.capabilities.spike_functions import get_spike_waveforms#check_match_front, inject_and_not_plot_model\n",
    "\n",
    "vms_hh = []\n",
    "for dtc in models_hh_r:\n",
    "    vms_hh.append(get_spike_waveforms(inject_and_not_plot_model(dtc)))\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "#figure(num=None, figsize=(50, 50), dpi=80)#, facecolor='w', edgecolor='k')\n",
    "plt.figure(figsize=(12, 12))\n",
    "print(len(vms_hh),len(models_hh))\n",
    "for v,f in zip(vms_hh,models_hh_r):\n",
    "    name = str(f.name)\n",
    "    try:\n",
    "        name2 = name.split('dump_hh_')[1]\n",
    "    except:\n",
    "        name2 = name\n",
    "    plt.plot(v.times, v.magnitude,label=name2)\n",
    "plt.xlabel('Time (ms)')\n",
    "\n",
    "plt.ylabel('V (mV)')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vms_izhi = []\n",
    "for dtc in models_izhi:\n",
    "    dtc.backend = \"IZHI\"\n",
    "    vms_izhi.append(get_spike_waveforms(inject_and_not_plot_model(dtc)))\n",
    "\n",
    "plt.figure(figsize=(12, 12), dpi=80)\n",
    "print(len(vms_izhi),len(models_izhi))\n",
    "#figure(num=None, figsize=(125, 125), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "for v,f in zip(vms_izhi,models_izhi):\n",
    "    name = str(f.name)\n",
    "    try:\n",
    "        name2 = name.split('dump_izhi_')[1]\n",
    "    except:\n",
    "        name2 = name\n",
    "    plt.plot(v.times, v.magnitude,label=name2)\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "\n",
    "plt.ylabel('V (mV)')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12), dpi=80)\n",
    "colors = ['b','g','r','y']\n",
    "cnt = 0\n",
    "for v0,f0,v1,f1 in zip(vms_hh,models_hh_r,vms_izhi,models_izhi):\n",
    "    name = str(f0.name)\n",
    "    try:\n",
    "        name2 = name.split('dump_hh_')[1]\n",
    "    except:\n",
    "        name2 = name\n",
    "    plt.plot(v0.times, v0.magnitude,label=name2,c=colors[cnt])\n",
    "    plt.plot(v1.times, v1.magnitude,c=colors[cnt])\n",
    "\n",
    "    plt.xlabel('Time (ms)')\n",
    "\n",
    "    plt.ylabel('V (mV)')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_columns',None)\n",
    "pd.set_option('max_rows',None)\n",
    "#pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "\n",
    "for f0,f1 in zip(models_hh_r,models_izhi):\n",
    "    name2 = str(f0.name)\n",
    "    try:\n",
    "        name2 = name2.split('dump_')[1]\n",
    "    except:\n",
    "        name2 = name\n",
    "        \n",
    "    display(pd.DataFrame([{'test type':name2,'model type':f0.backend}]))    \n",
    "    f0.get_agreement()\n",
    "    df = f0.agreement\n",
    "    df = df.round(2)\n",
    "    display(df.round(2).T)\n",
    "    display(pd.DataFrame([{'test type':name2,'model type':f1.backend}]))    \n",
    "    f1.get_agreement()\n",
    "    df = f1.agreement\n",
    "    df = df.round(2)\n",
    "    display(df.round(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0.get_agreement()\n",
    "f0.agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "models_both = {}\n",
    "for f0,f1 in zip(models_hh_r,models_izhi):\n",
    "    models_both[str(f0)] = (f0,f1)\n",
    "    check_binary_match(f0,f1,snippets=False)\n",
    "'''    \n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns',None)\n",
    "pd.set_option('max_rows',None)\n",
    "\n",
    "list_of_dicts = []\n",
    "cnt = 0\n",
    "for f in all_files:\n",
    "    model = pickle.load(open(f,'rb'))\n",
    "\n",
    "    for t in model.tests:\n",
    "         \n",
    "        key = which_key(t.prediction)\n",
    "        temp = {'t.name':t.name,'prediction':t.prediction[key],'observation':t.observation['mean'],'model':model.backend}\n",
    "        list_of_dicts.append(temp)\n",
    "        '''\n",
    "        other = pd.DataFrame([temp]).T\n",
    "        if cnt>0:\n",
    "            other = pd.concat([other,other_old])\n",
    "        other_old = other\n",
    "        cnt+=1\n",
    "        '''\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "df\n",
    "#other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_binary_match(models[0],models[1],snippets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_binary_match(models[0],models[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_binary_match(models[4],models[2],snippets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "models[1].get_agreement()\n",
    "models[0].get_agreement()\n",
    "\n",
    "models[3].get_agreement()\n",
    "models[5].get_agreement()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].SA\n",
    "print(models[1].backend)\n",
    "models[1].agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[2].SA\n",
    "models[2].get_agreement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[2].backend\n",
    "models[2].backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[4].get_agreement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[2].SA.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[4].SA.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[4].SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "print = pprint\n",
    "print(models[4].attrs)\n",
    "print(models[4].tests[3].observation)#['CapacitanceTest'].observation\n",
    "print(models[0].tests[3].observation)#['CapacitanceTest'].observation\n",
    "print(models[1].tests[3].observation)#['CapacitanceTest'].observation\n",
    "print(models[2].tests[3].observation)#['CapacitanceTest'].observation\n",
    "print(models[3].tests[3].observation)#['CapacitanceTest'].observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[4].attrs['C'] = 100.796\n",
    "models[4].self_evaluate()\n",
    "models[4].SA\n",
    "models[4].get_agreement()\n",
    "models[4].agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Izhi model remains an art, with human intervention.\n",
    "It can not be automated.\n",
    "# Capacitance is not felt properly,\n",
    "unless k,a,b and are right.\n",
    "Spike width and time constant is wrong.\n",
    "The width is 3 times too big.\n",
    "and the time constant 3 times too small.\n",
    "It would be better to optimize on \n",
    "'C', 'Width', 'TC'. Alone with just altering 'C', 'k', 'b','a'.\n",
    "\n",
    "Optimize Rheobase, Input resistance, and AP Threshold seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "models[4].attrs['k'] \n",
    "models[4].attrs['k']  = 0.25\n",
    "models[4].self_evaluate()\n",
    "models[4].SA\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(models[4].attrs['b'])\n",
    "models[4].attrs['b']  = 5.25\n",
    "models[4].self_evaluate()\n",
    "models[4].SA\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_binary_match(models[2],models[3],snippets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_binary_match(models[2],models[3],snippets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[3].attrs\n",
    "models[2].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggesting vr does not do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation import model_parameters\n",
    "hh = model_parameters.MODEL_PARAMS[\"NEURONHH\"]\n",
    "hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.optimization_management import check_match_front, inject_and_not_plot_model\n",
    "dtcpop_hh = [models[0],models[3],models[4]]\n",
    "dtcpop_izhi = [models[1],models[2],models[5]]\n",
    "\n",
    "plt = check_match_front(models[0],dtcpop_hh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vms = []\n",
    "for dtc in dtcpop_hh:\n",
    "    vms.append(inject_and_not_plot_model(dtc))\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for v in vms:\n",
    "    plt.plot(v.times, v.magnitude)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "for i in models:\n",
    "    for t in i.tests:\n",
    "        key = which_key(t.prediction)\n",
    "        list_of_dicts.append({'t.name':t.name,'prediction':t.prediction[key],'observation':t.observation['mean'],'model':i.backend})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_of_dicts)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
