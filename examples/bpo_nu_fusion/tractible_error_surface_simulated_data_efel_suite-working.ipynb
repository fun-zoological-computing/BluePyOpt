{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we remove all but one parameter from the dictionary of free parameters.\n",
    "\n",
    "Parameters \"popped\" from this dictionary are frozen only 'a' is left and free to vary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we pick a random point between \n",
    "a=0.01 and a=0.03\n",
    "we instance a model at this random location in a. \n",
    "We then find rheobase and take efel measurements at 1.5 and 3.0 rheobase for the Izhikitich model. \n",
    "\n",
    "Then we use GA optimization to find the model that produced the measurements, as a type of inversion.\n",
    "\n",
    "Jump to cells 27 and 28. You can see there that \n",
    "\n",
    "the error surface is highly intractable for some measurements, and for other measurements its a simple well with no ripples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random simulated data tests made\n",
      "allen cell 504615116\n"
     ]
    }
   ],
   "source": [
    "import efel\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "list(efel.getFeatureNames());\n",
    "from utils import dask_map_function\n",
    "\n",
    "import bluepyopt as bpop\n",
    "import bluepyopt.ephys as ephys\n",
    "import pickle\n",
    "from sciunit.scores import ZScore\n",
    "from sciunit import TestSuite\n",
    "from sciunit.scores.collections import ScoreArray\n",
    "import sciunit\n",
    "import numpy as np\n",
    "from neuronunit.optimisation.optimization_management import dtc_to_rheo, switch_logic,active_values\n",
    "from neuronunit.tests.base import AMPL, DELAY, DURATION\n",
    "\n",
    "import quantities as pq\n",
    "PASSIVE_DURATION = 500.0*pq.ms\n",
    "PASSIVE_DELAY = 200.0*pq.ms\n",
    "import matplotlib.pyplot as plt\n",
    "from bluepyopt.ephys.models import ReducedCellModel\n",
    "import numpy\n",
    "from neuronunit.optimisation.optimization_management import test_all_objective_test\n",
    "from neuronunit.optimisation.optimization_management import check_binary_match, three_step_protocol,inject_and_plot_passive_model\n",
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "simple_cell = ephys.models.ReducedCellModel(\n",
    "        name='simple_cell',\n",
    "        params=MODEL_PARAMS[\"IZHI\"],backend=\"IZHI\")  \n",
    "simple_cell.backend = \"IZHI\"\n",
    "\n",
    "\n",
    "# Now we can print out a description of the cell\n",
    "\n",
    "model = simple_cell\n",
    "model.params = {k:np.mean(v) for k,v in model.params.items() }\n",
    "from make_allen_tests import AllenTest\n",
    "\n",
    "from sciunit.scores import ZScore\n",
    "tests = pickle.load(open(\"processed_multicellular_constraints.p\",\"rb\"))\n",
    "nu_tests = tests['Hippocampus CA1 pyramidal cell'].tests\n",
    "nu_tests[0].score_type = ZScore\n",
    "\n",
    "simulated_experiment = True\n",
    "features = None\n",
    "allen = True\n",
    "from collections.abc import Iterable\n",
    "\n",
    "if simulated_experiment:\n",
    "    while features is None:\n",
    "        aug_nu_tests, OM, target = test_all_objective_test(MODEL_PARAMS[\"IZHI\"],\n",
    "                                                           model_type=\"IZHI\",\n",
    "                                                           protocol={'allen':False,\n",
    "                                                                     'elephant':True})\n",
    "        target = three_step_protocol(target)\n",
    "        if hasattr(target,'everything'):\n",
    "            features = copy.copy(target.everything)\n",
    "            \n",
    "            check_list = {key:feat for key,feat in features.items() if not feat is None and type(feat) is not type(Iterable) and feat !=0 and feat !=1 }\n",
    "            check_list.pop('depol_block_1.5x',None)\n",
    "            check_list.pop('is_not_stuck_3.0x',None)\n",
    "            check_list.pop('is_not_stuck_1.5x',None)\n",
    "            scale = 2.0/len(check_list)\n",
    "            '''\n",
    "            if scale > 0.009999:\n",
    "                print('not high enough definition')\n",
    "                features = None\n",
    "                continue\n",
    "            '''\n",
    "            if allen:\n",
    "                simple_cell.allen = None\n",
    "                simple_cell.allen = True\n",
    "\n",
    "                tests = pickle.load(open(\"allen_NU_tests.p\",\"rb\"))\n",
    "                print('allen cell',tests[0].name)\n",
    "                nu_tests = tests[0]\n",
    "                for t in nu_tests:\n",
    "                    to_pop = []\n",
    "                    if t.name in features.keys():\n",
    "                        if features[t.name] is not None:\n",
    "                            t.set_observation(features[t.name])\n",
    "                            if t.observation['mean'] is not None:\n",
    "                                t.observation['std'] = np.abs(np.mean(t.observation['mean']))\n",
    "                        to_pop.append(t.name)\n",
    "                        \n",
    "                    [ features.pop(i,None) for i in to_pop ]\n",
    "\n",
    "sub_MODEL_PARAMS = copy.copy(MODEL_PARAMS['IZHI'])\n",
    "\n",
    "subset = list(sub_MODEL_PARAMS.keys())\n",
    "tg = target.dtc_to_gene(subset_params=subset)\n",
    "assert len(tg)==len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'value': array(316.40625) * pA,\n",
       " 'std': array(170.45245472) * pA,\n",
       " 'mean': array(316.40625) * pA}"
=======
       "{'value': array(268.39599609) * pA,\n",
       " 'std': array(170.45245472) * pA,\n",
       " 'mean': array(268.39599609) * pA}"
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.rheobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = target.everything\n",
    "\n",
    "\n",
    "for key,feat in features.items():\n",
    "    if isinstance(feat, int):\n",
    "        print(key,feat)\n",
    "features\n",
    "nu_tests;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "big_list = []\n",
    "for tt in aug_nu_tests.values():\n",
    "    tt.core = None\n",
    "    tt.core = True\n",
    "    big_list.append(tt)\n",
    "big_list.extend(nu_tests)\n",
    "nu_tests = big_list\n",
    "aug_nu_tests = list(aug_nu_tests.values())[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -ltr *.p\n",
    "import pickle\n",
    "\n",
    "no_list = pickle.load(open(\"too_rippled_b.p\",\"rb\"))\n",
    "yes_list = pickle.load(open(\"tame_b.p\",\"rb\"))\n",
<<<<<<< HEAD
    "#yes_list ='RheobaseTest'\n",
    "yes_list = ['AHP_depth_abs_3.0x','sag_ratio2_3.0x','ohmic_input_resistance_1.5x','sag_ratio2_1.5x','peak_voltage_3.0x','peak_voltage_1.5x','voltage_base_3.0x','voltage_base_1.5x','Spikecount_1.5x','Spikecount_3.0x','ohmic_input_resistance_vb_ssse_1.5x']\n",
    "#yes_list"
=======
    "#yes_list\n",
    "yes_list = ['RheobaseTest','sag_ratio2_1.5x','peak_voltage_3.0x','peak_voltage_1.5x','voltage_base_3.0x','voltage_base_1.5x','Spikecount_1.5x','Spikecount_3.0x','ohmic_input_resistance_vb_ssse_1.5x']"
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "#yes_list = pickle.load(open(\"tame_b.p\",\"rb\"))\n",
    "#yes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
=======
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "#yes_list = ['peak_voltage_3.0x','voltage_base_1.5x','ohmic_input_resistance_vb_ssse_1.5x','Spint(kecount_1.5x','Spikecount_3.0x']\n",
    "#yes_list = pickle.load(open(\"tame_b.p\",\"rb\"))\n",
    "\n",
    "#yes_list"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 8,
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'C': <bluepyopt.parameters.Parameter object at 0x7f75eb195690>, 'k': <bluepyopt.parameters.Parameter object at 0x7f75d6a98710>, 'vr': <bluepyopt.parameters.Parameter object at 0x7f75d6a98850>, 'vt': <bluepyopt.parameters.Parameter object at 0x7f75d6a984d0>, 'vPeak': <bluepyopt.parameters.Parameter object at 0x7f75d6a98750>, 'a': <bluepyopt.parameters.Parameter object at 0x7f75d6a98950>, 'b': <bluepyopt.parameters.Parameter object at 0x7f75d6a98a10>, 'c': <bluepyopt.parameters.Parameter object at 0x7f75d6a988d0>, 'd': <bluepyopt.parameters.Parameter object at 0x7f75d6a98ad0>}\n"
=======
      "{'C': <bluepyopt.parameters.Parameter object at 0x7fe39dd54350>, 'k': <bluepyopt.parameters.Parameter object at 0x7fe39dd54450>, 'vr': <bluepyopt.parameters.Parameter object at 0x7fe39dd542d0>, 'vt': <bluepyopt.parameters.Parameter object at 0x7fe39dd54410>, 'vPeak': <bluepyopt.parameters.Parameter object at 0x7fe39dd54510>, 'a': <bluepyopt.parameters.Parameter object at 0x7fe39dd545d0>, 'b': <bluepyopt.parameters.Parameter object at 0x7fe39dd54390>, 'c': <bluepyopt.parameters.Parameter object at 0x7fe39dd54810>, 'd': <bluepyopt.parameters.Parameter object at 0x7fe39dd54750>}\n"
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
     ]
    }
   ],
   "source": [
    "from sciunit.scores import ZScore\n",
    " \n",
    "class NUFeatureAllenMultiSpike(object):\n",
    "    def __init__(self,test,model,cnt,target,check_list,spike_obs,print_stuff=False):\n",
    "        self.test = test\n",
    "        self.model = model\n",
    "        self.check_list = check_list\n",
    "        self.spike_obs = spike_obs\n",
    "        self.cnt = cnt\n",
    "        self.target = target\n",
    "        self.print_stuff = print_stuff\n",
    "    def calculate_score(self,responses):\n",
    "        if not 'features' in responses.keys():# or not 'model' in responses.keys():\n",
    "            return 1000.0\n",
    "        check_list = self.check_list\n",
    "        #print(self.test.name)\n",
    "    \n",
    "        features = responses['features']\n",
<<<<<<< HEAD
    "        if False:\n",
    "            #if self.test.name in \"RheobaseTest\":\n",
=======
    "        #if False:\n",
    "        if self.test.name in \"RheobaseTest\":\n",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "            self.test.set_prediction(responses['rheobase'])   \n",
    "            self.test.prediction['value'] = self.test.prediction['mean']\n",
    "            self.test.observation['std'] = np.abs(np.mean(self.target.rheobase['mean']))\n",
    "            self.test.observation['mean'] = np.mean(self.test.observation['mean'])   \n",
    "            self.test.observation['value'] = np.mean(self.test.observation['value'])   \n",
    "\n",
    "            self.test.score_type = ZScore\n",
    "\n",
    "            score_gene = self.test.compute_score(self.test.prediction,self.test.observation)\n",
    "            if score_gene is not None:\n",
    "                if score_gene.log_norm_score is not None:\n",
    "                    delta = np.abs(float(score_gene.log_norm_score))\n",
    "                else:\n",
    "                    if score_gene.raw is not None:\n",
    "                        delta = np.abs(float(score_gene.raw))\n",
    "                    else:\n",
    "                        delta = None\n",
    "            else:\n",
    "                delta = None\n",
    "            if delta is None:\n",
    "                delta = np.abs(np.float(responses['rheobase'])-np.mean(self.test.observation['mean']))\n",
    "            if np.nan==delta or delta==np.inf:\n",
    "                delta = np.abs(np.float(responses['rheobase'])-np.mean(self.test.observation['mean']))\n",
    "\n",
    "            return delta\n",
    "\n",
    "        feature_name = self.test.name\n",
    "        delta0 = np.abs(features['Spikecount_3.0x']-np.mean(self.spike_obs[0]['mean']))\n",
    "        delta1 = np.abs(features['Spikecount_1.5x']-np.mean(self.spike_obs[1]['mean']))\n",
    "        if feature_name not in features.keys():\n",
    "            return 1000.0+(delta0+delta1)\n",
    "        \n",
    "        if features[feature_name] is None:\n",
    "            return 1000.0+(delta0+delta1)\n",
    "            \n",
    "        if type(features[self.test.name]) is type(Iterable):\n",
    "            features[self.test.name] = np.mean(features[self.test.name])\n",
    "        self.test.observation['std'] = np.abs(np.mean(self.test.observation['mean']))\n",
    "        self.test.observation['mean'] = np.mean(self.test.observation['mean'])   \n",
    "        self.test.set_prediction(np.mean(features[self.test.name]))\n",
    "\n",
    "        if 'Spikecount_3.0x'==feature_name or 'Spikecount_1.5x'==feature_name:\n",
    "            delta = np.abs(features[self.test.name]-np.mean(self.test.observation['mean']))\n",
    "            if np.nan==delta or delta==np.inf:\n",
    "                delta = 1000.0\n",
    "\n",
    "            \n",
    "            return delta\n",
    "        else:\n",
    "\n",
    "\n",
    "            if feature_name in check_list:\n",
    "                if features[feature_name] is None:\n",
    "                    return 1000.0+(delta0+delta1)\n",
    "                self.test.score_type = ZScore\n",
    "                score_gene = self.test.feature_judge()\n",
    "                if score_gene is not None:\n",
    "                    if score_gene.log_norm_score is not None:\n",
    "                        delta = np.abs(float(score_gene.log_norm_score))\n",
    "                    else:\n",
    "                        if score_gene.raw is not None:\n",
    "                            delta = np.abs(float(score_gene.raw))\n",
    "                        else:\n",
    "                            delta = None\n",
    "\n",
    "                else:\n",
    "                    delta = None\n",
    "                        #if delta==np.inf or np.isnan(delta):\n",
    "                        #    if score_gene.raw is not None:\n",
    "                        #        delta =  np.abs(float(score_gene.raw))\n",
    "                if delta is None:\n",
    "                    delta = np.abs(features[self.test.name]-np.mean(self.test.observation['mean']))\n",
    "\n",
    "\n",
    "                if np.nan==delta or delta==np.inf:\n",
    "                    delta = np.abs(features[self.test.name]-np.mean(self.test.observation['mean']))\n",
    "                if np.nan==delta or delta==np.inf:\n",
    "                    delta = 1000.0\n",
    "                return delta#+delta2\n",
    "            else:\n",
    "                return 0.0\n",
    "   \n",
    "objectives = []\n",
    "spike_obs = []\n",
    "for tt in nu_tests:\n",
    "    if 'Spikecount_3.0x' == tt.name:\n",
    "        spike_obs.append(tt.observation)\n",
    "    if 'Spikecount_1.5x' == tt.name:\n",
    "        spike_obs.append(tt.observation)\n",
    "spike_obs = sorted(spike_obs, key=lambda k: k['mean'],reverse=True)\n",
<<<<<<< HEAD
    "\n",
=======
    "'''             \n",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "check_list[\"RheobaseTest\"] = target.rheobase['value']\n",
    "for cnt,tt in enumerate(nu_tests):\n",
    "    feature_name = '%s' % (tt.name)\n",
    "    if feature_name in check_list:\n",
    "        if 'Spikecount_3.0x' == tt.name or 'Spikecount_1.5x' == tt.name:\n",
    "            ft = NUFeatureAllenMultiSpike(tt,model,cnt,target,check_list,spike_obs)\n",
    "            objective = ephys.objectives.SingletonObjective(\n",
    "                feature_name,\n",
    "                ft)\n",
    "            objectives.append(objective)\n",
    "\n",
<<<<<<< HEAD
    "\n",
=======
    "'''\n",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "        \n",
    "score_calc = ephys.objectivescalculators.ObjectivesCalculator(objectives) \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lop={}\n",
    "from bluepyopt.parameters import Parameter\n",
    "for k,v in MODEL_PARAMS[\"IZHI\"].items():\n",
    "    p = Parameter(name=k,bounds=v,frozen=False)\n",
    "    lop[k] = p\n",
    "\n",
    "print(lop)\n",
    "simple_cell.params = lop\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 9,
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list;"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 10,
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noptimisation = bpop.optimisations.DEAPOptimisation(\\n        evaluator=cell_evaluator,\\n        offspring_size = MU,\\n        map_function = dask_map_function,\\n        selector_name='NSGA2',mutpb=0.5,cxpb=0.5)\\n\\nfinal_pop, hall_of_fame, logs, hist = optimisation.run(max_ngen=150)\\ncp = {}\\ncp['hall_of_fame'] = hall_of_fame\\ncp['final_pop'] = final_pop\\n\\n\""
      ]
     },
<<<<<<< HEAD
     "execution_count": 11,
=======
     "execution_count": 10,
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import dask_map_function\n",
    "\n",
    "# Combining everything together we have a CellEvaluator. The CellEvaluator constructor has a field 'parameter_names' which contains the (ordered) list of names of the parameters that are used as input (and will be fitted later on).\n",
    "sweep_protocols = []\n",
    "for protocol_name, amplitude in [('step1', 0.05)]:\n",
    "\n",
    "    protocol = ephys.protocols.SweepProtocol(protocol_name, [None], [None])\n",
    "    sweep_protocols.append(protocol)\n",
    "twostep_protocol = ephys.protocols.SequenceProtocol('twostep', protocols=sweep_protocols)\n",
    "\n",
    "simple_cell.params_by_names(MODEL_PARAMS[\"IZHI\"].keys())\n",
    "simple_cell.params;\n",
    "\n",
    "\n",
    "MODEL_PARAMS[\"IZHI\"]\n",
    "cell_evaluator = ephys.evaluators.CellEvaluator(\n",
    "        cell_model=simple_cell,\n",
    "        param_names=MODEL_PARAMS[\"IZHI\"].keys(),\n",
    "        fitness_protocols={twostep_protocol.name: twostep_protocol},\n",
    "        fitness_calculator=score_calc,\n",
    "        sim='euler')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "simple_cell.params_by_names(MODEL_PARAMS[\"IZHI\"].keys())\n",
    "\n",
    "simple_cell.params;\n",
    "\n",
    "\n",
    "#optimisation = bpop.optimisations.DEAPOptimisation(\n",
    "#        evaluator=cell_evaluator,\n",
    "#        offspring_size = MU,\n",
    "#        map_function = dask_map_function,\n",
    "#        selector_name='NSGA2',mutpb=0.2,cxpb=0.45)\n",
    "'''\n",
    "optimisation = bpop.optimisations.DEAPOptimisation(\n",
    "        evaluator=cell_evaluator,\n",
    "        offspring_size = MU,\n",
    "        map_function = dask_map_function,\n",
    "        selector_name='NSGA2',mutpb=0.5,cxpb=0.5)\n",
    "\n",
    "final_pop, hall_of_fame, logs, hist = optimisation.run(max_ngen=150)\n",
    "cp = {}\n",
    "cp['hall_of_fame'] = hall_of_fame\n",
    "cp['final_pop'] = final_pop\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 11,
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbest_ind = hall_of_fame[0]\\nbest_ind_dict = cell_evaluator.param_dict(best_ind)\\nmodel = cell_evaluator.cell_model\\ncell_evaluator.param_dict(best_ind)\\n\\nmodel.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\\nopt = model.model_to_dtc()\\nopt.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\\ntarget\\n\\nfrom neuronunit.optimisation.optimization_management import dtc_to_rheo, inject_and_plot_model30,check_bin_vm30,check_bin_vm15\\n\\nvm301,vm151,_,_,target = inject_and_plot_model30(target)\\nvm302,vm152,_,_,opt = inject_and_plot_model30(opt)\\ncheck_bin_vm30(target,opt)\\ncheck_bin_vm15(target,opt)\\n'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 12,
=======
     "execution_count": 11,
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "best_ind = hall_of_fame[0]\n",
    "best_ind_dict = cell_evaluator.param_dict(best_ind)\n",
    "model = cell_evaluator.cell_model\n",
    "cell_evaluator.param_dict(best_ind)\n",
    "\n",
    "model.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "opt = model.model_to_dtc()\n",
    "opt.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "target\n",
    "\n",
    "from neuronunit.optimisation.optimization_management import dtc_to_rheo, inject_and_plot_model30,check_bin_vm30,check_bin_vm15\n",
    "\n",
    "vm301,vm151,_,_,target = inject_and_plot_model30(target)\n",
    "vm302,vm152,_,_,opt = inject_and_plot_model30(opt)\n",
    "check_bin_vm30(target,opt)\n",
    "check_bin_vm15(target,opt)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:gen\tnevals\tavg    \tstd    \tmin    \tmax  \n",
      "1  \t50    \t1744.48\t3606.86\t21.4858\t10000\n",
      "gen\tnevals\tavg    \tstd    \tmin    \tmax  \n",
      "1  \t50    \t1744.48\t3606.86\t21.4858\t10000\n"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RheobaseTest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:gen\tnevals\tavg    \tstd    \tmin    \tmax \n",
      "1  \t50    \t1545.74\t3257.54\t8.97848\t9000\n",
      "gen\tnevals\tavg    \tstd    \tmin    \tmax \n",
      "1  \t50    \t1545.74\t3257.54\t8.97848\t9000\n"
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "9ca5afe948ed4f06ae870f755b4d0b3e",
=======
       "model_id": "c871cfa3d7fe45bfbb79c57eaaf4515f",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
<<<<<<< HEAD
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
=======
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "INFO:__main__:2  \t16    \t2102.35\t3926.74\t20.3226\t10000\n",
      "2  \t16    \t2102.35\t3926.74\t20.3226\t10000\n",
      "INFO:__main__:3  \t22    \t185.676\t987.938\t14.2554\t10000\n",
      "3  \t22    \t185.676\t987.938\t14.2554\t10000\n",
      "INFO:__main__:4  \t17    \t33.6045\t18.1939\t14.2554\t113.756\n",
      "4  \t17    \t33.6045\t18.1939\t14.2554\t113.756\n",
      "INFO:__main__:5  \t15    \t28.9147\t11.7059\t14.2554\t77.752 \n",
      "5  \t15    \t28.9147\t11.7059\t14.2554\t77.752 \n",
      "INFO:__main__:6  \t22    \t36.7083\t18.3932\t14.2554\t77.7623\n",
      "6  \t22    \t36.7083\t18.3932\t14.2554\t77.7623\n",
      "INFO:__main__:7  \t21    \t31.7386\t12.94  \t14.2054\t65.567 \n",
      "7  \t21    \t31.7386\t12.94  \t14.2054\t65.567 \n",
      "INFO:__main__:8  \t24    \t45.9992\t149.597\t8.27342\t1110.84\n",
      "8  \t24    \t45.9992\t149.597\t8.27342\t1110.84\n",
      "INFO:__main__:9  \t22    \t112.078\t290.043\t8.27342\t1110.84\n",
      "9  \t22    \t112.078\t290.043\t8.27342\t1110.84\n",
      "INFO:__main__:10 \t20    \t36.5137\t106.788\t4.16068\t1098.62\n",
      "10 \t20    \t36.5137\t106.788\t4.16068\t1098.62\n",
      "INFO:__main__:11 \t19    \t33.8536\t107.323\t4.16068\t1098.62\n",
      "11 \t19    \t33.8536\t107.323\t4.16068\t1098.62\n",
      "INFO:__main__:12 \t17    \t22.5556\t10.7738\t4.16068\t57.0196\n",
      "12 \t17    \t22.5556\t10.7738\t4.16068\t57.0196\n",
      "INFO:__main__:13 \t20    \t31.9132\t100.035\t4.16068\t1026.66\n",
      "13 \t20    \t31.9132\t100.035\t4.16068\t1026.66\n",
      "INFO:__main__:14 \t16    \t62.0085\t196.324\t4.16068\t1026.66\n",
      "14 \t16    \t62.0085\t196.324\t4.16068\t1026.66\n",
      "INFO:__main__:15 \t20    \t148.659\t337.765\t4.0243 \t1030.56\n",
      "15 \t20    \t148.659\t337.765\t4.0243 \t1030.56\n",
      "INFO:__main__:16 \t17    \t17.7046\t11.7134\t4.0243 \t83.4238\n",
      "16 \t17    \t17.7046\t11.7134\t4.0243 \t83.4238\n",
      "INFO:__main__:17 \t23    \t24.4124\t14.5127\t3.19979\t83.4238\n",
      "17 \t23    \t24.4124\t14.5127\t3.19979\t83.4238\n",
      "INFO:__main__:18 \t15    \t20.6218\t16.479 \t3.19979\t88.6588\n",
      "18 \t15    \t20.6218\t16.479 \t3.19979\t88.6588\n",
      "INFO:__main__:19 \t24    \t27.8733\t18.3271\t3.19979\t88.6588\n",
      "19 \t24    \t27.8733\t18.3271\t3.19979\t88.6588\n",
      "INFO:__main__:20 \t15    \t25.9343\t18.417 \t3.19979\t88.6588\n",
      "20 \t15    \t25.9343\t18.417 \t3.19979\t88.6588\n",
      "INFO:__main__:21 \t28    \t26.5377\t19.8723\t3.19979\t90.3017\n",
      "21 \t28    \t26.5377\t19.8723\t3.19979\t90.3017\n",
      "INFO:__main__:22 \t17    \t23.5387\t18.6344\t3.14347\t90.3017\n",
      "22 \t17    \t23.5387\t18.6344\t3.14347\t90.3017\n",
      "INFO:__main__:23 \t21    \t29.8104\t21.4845\t3.14347\t105.539\n",
      "23 \t21    \t29.8104\t21.4845\t3.14347\t105.539\n",
      "INFO:__main__:24 \t16    \t32.1953\t26.4612\t3.14347\t155.651\n",
      "24 \t16    \t32.1953\t26.4612\t3.14347\t155.651\n",
      "INFO:__main__:25 \t21    \t19.969 \t15.9758\t0.622857\t90.3017\n",
      "25 \t21    \t19.969 \t15.9758\t0.622857\t90.3017\n",
      "INFO:__main__:26 \t17    \t17.659 \t14.5186\t0.622857\t90.3017\n",
      "26 \t17    \t17.659 \t14.5186\t0.622857\t90.3017\n",
      "INFO:__main__:27 \t16    \t18.4922\t11.1315\t0.622857\t90.3017\n",
      "27 \t16    \t18.4922\t11.1315\t0.622857\t90.3017\n",
      "INFO:__main__:28 \t12    \t11.9071\t8.38505\t0.622857\t31.1948\n",
      "28 \t12    \t11.9071\t8.38505\t0.622857\t31.1948\n",
      "INFO:__main__:29 \t18    \t14.6864\t7.54887\t0.622857\t46.7783\n",
      "29 \t18    \t14.6864\t7.54887\t0.622857\t46.7783\n",
      "INFO:__main__:30 \t19    \t14.7502\t7.83597\t0.622857\t33.3377\n",
      "30 \t19    \t14.7502\t7.83597\t0.622857\t33.3377\n",
      "INFO:__main__:31 \t22    \t16.3787\t10.3911\t0.622857\t50.5517\n",
      "31 \t22    \t16.3787\t10.3911\t0.622857\t50.5517\n",
      "INFO:__main__:32 \t18    \t15.8175\t10.4383\t0.622857\t51.5233\n",
      "32 \t18    \t15.8175\t10.4383\t0.622857\t51.5233\n",
      "INFO:__main__:33 \t16    \t22.686 \t102.155\t0.622857\t1040.8 \n",
      "33 \t16    \t22.686 \t102.155\t0.622857\t1040.8 \n",
      "INFO:__main__:34 \t19    \t9.94774\t9.28551\t0.622857\t68.8231\n",
      "34 \t19    \t9.94774\t9.28551\t0.622857\t68.8231\n",
      "INFO:__main__:35 \t27    \t13.7633\t10.9575\t0.622857\t68.8231\n",
      "35 \t27    \t13.7633\t10.9575\t0.622857\t68.8231\n",
      "INFO:__main__:36 \t18    \t22.4978\t100.855\t0.622857\t1026.64\n",
      "36 \t18    \t22.4978\t100.855\t0.622857\t1026.64\n",
      "INFO:__main__:37 \t18    \t9.42145\t6.44272\t0.622857\t38.9715\n",
      "37 \t18    \t9.42145\t6.44272\t0.622857\t38.9715\n",
      "INFO:__main__:38 \t15    \t7.22795\t5.00412\t0.622857\t26.2698\n",
      "38 \t15    \t7.22795\t5.00412\t0.622857\t26.2698\n",
      "INFO:__main__:39 \t9     \t9.29182\t5.94857\t0.622857\t30.6949\n",
      "39 \t9     \t9.29182\t5.94857\t0.622857\t30.6949\n",
      "INFO:__main__:40 \t19    \t9.07203\t8.12402\t0.622857\t54.916 \n",
      "40 \t19    \t9.07203\t8.12402\t0.622857\t54.916 \n",
      "INFO:__main__:41 \t17    \t11.4186\t8.3684 \t0.622857\t27.5081\n",
      "41 \t17    \t11.4186\t8.3684 \t0.622857\t27.5081\n",
      "INFO:__main__:42 \t19    \t10.7535\t7.33966\t0.311116\t26.7788\n",
      "42 \t19    \t10.7535\t7.33966\t0.311116\t26.7788\n",
      "INFO:__main__:43 \t19    \t9.57474\t5.60995\t0.31111 \t26.7788\n",
      "43 \t19    \t9.57474\t5.60995\t0.31111 \t26.7788\n",
      "INFO:__main__:44 \t14    \t10.968 \t8.46934\t0.31111 \t47.4871\n",
      "44 \t14    \t10.968 \t8.46934\t0.31111 \t47.4871\n",
      "INFO:__main__:45 \t17    \t9.77206\t5.87327\t0.31111 \t26.7788\n",
      "45 \t17    \t9.77206\t5.87327\t0.31111 \t26.7788\n",
      "INFO:__main__:46 \t19    \t8.01512\t5.33214\t0.31111 \t28.7247\n",
      "46 \t19    \t8.01512\t5.33214\t0.31111 \t28.7247\n",
      "INFO:__main__:47 \t22    \t6.55323\t3.84031\t0.31111 \t26.3765\n",
      "47 \t22    \t6.55323\t3.84031\t0.31111 \t26.3765\n",
      "INFO:__main__:48 \t17    \t6.4218 \t5.59746\t0.31111 \t50.298 \n",
      "48 \t17    \t6.4218 \t5.59746\t0.31111 \t50.298 \n",
      "INFO:__main__:49 \t20    \t5.45232\t5.27891\t0.31111 \t41.9363\n",
      "49 \t20    \t5.45232\t5.27891\t0.31111 \t41.9363\n",
      "INFO:__main__:50 \t20    \t7.28256\t8.20016\t0.31111 \t49.5938\n",
      "50 \t20    \t7.28256\t8.20016\t0.31111 \t49.5938\n",
      "INFO:__main__:51 \t18    \t6.49702\t7.01474\t0.31111 \t42.455 \n",
      "51 \t18    \t6.49702\t7.01474\t0.31111 \t42.455 \n",
      "INFO:__main__:52 \t18    \t7.03422\t6.17088\t0.31111 \t44.4669\n",
      "52 \t18    \t7.03422\t6.17088\t0.31111 \t44.4669\n",
      "INFO:__main__:53 \t16    \t5.74885\t4.52853\t0.31111 \t20.2445\n",
      "53 \t16    \t5.74885\t4.52853\t0.31111 \t20.2445\n",
      "INFO:__main__:54 \t17    \t7.30351\t5.36874\t0.31111 \t25.6739\n",
      "54 \t17    \t7.30351\t5.36874\t0.31111 \t25.6739\n",
      "INFO:__main__:55 \t17    \t7.07442\t4.42887\t0.31111 \t20.8997\n",
      "55 \t17    \t7.07442\t4.42887\t0.31111 \t20.8997\n",
      "INFO:__main__:56 \t17    \t9.82066\t6.70792\t0.31111 \t38.2429\n",
      "56 \t17    \t9.82066\t6.70792\t0.31111 \t38.2429\n",
      "INFO:__main__:57 \t16    \t7.05144\t7.15533\t0.31111 \t37.6283\n",
      "57 \t16    \t7.05144\t7.15533\t0.31111 \t37.6283\n",
      "INFO:__main__:58 \t13    \t9.06014\t8.36866\t0.31111 \t46.5572\n",
      "58 \t13    \t9.06014\t8.36866\t0.31111 \t46.5572\n",
      "INFO:__main__:59 \t23    \t9.41756\t9.80542\t0.31111 \t37.6283\n",
      "59 \t23    \t9.41756\t9.80542\t0.31111 \t37.6283\n",
      "INFO:__main__:60 \t11    \t7.11345\t7.80729\t0.31111 \t37.6283\n",
      "60 \t11    \t7.11345\t7.80729\t0.31111 \t37.6283\n",
      "INFO:__main__:61 \t18    \t6.12363\t6.30026\t0.31111 \t30.2501\n",
      "61 \t18    \t6.12363\t6.30026\t0.31111 \t30.2501\n",
      "INFO:__main__:62 \t13    \t8.86125\t9.75646\t0.31111 \t35.6277\n",
      "62 \t13    \t8.86125\t9.75646\t0.31111 \t35.6277\n",
      "INFO:__main__:63 \t20    \t6.87447\t7.84176\t0.31111 \t39.7117\n",
      "63 \t20    \t6.87447\t7.84176\t0.31111 \t39.7117\n",
      "INFO:__main__:64 \t13    \t5.19256\t4.76819\t0.31111 \t24.9541\n",
      "64 \t13    \t5.19256\t4.76819\t0.31111 \t24.9541\n",
      "INFO:__main__:65 \t17    \t4.33264\t5.74669\t0.31111 \t28.6123\n",
      "65 \t17    \t4.33264\t5.74669\t0.31111 \t28.6123\n",
      "INFO:__main__:66 \t20    \t5.0138 \t5.14278\t0.31111 \t25.5632\n",
      "66 \t20    \t5.0138 \t5.14278\t0.31111 \t25.5632\n",
      "INFO:__main__:67 \t21    \t4.75274\t3.84161\t0.31111 \t22.2689\n",
      "67 \t21    \t4.75274\t3.84161\t0.31111 \t22.2689\n",
      "INFO:__main__:68 \t22    \t7.26876\t5.5291 \t0.31111 \t31.0835\n",
      "68 \t22    \t7.26876\t5.5291 \t0.31111 \t31.0835\n",
      "INFO:__main__:69 \t16    \t7.52389\t6.698  \t0.31111 \t25.1602\n",
      "69 \t16    \t7.52389\t6.698  \t0.31111 \t25.1602\n",
      "INFO:__main__:70 \t16    \t5.47219\t4.79426\t0.31111 \t20.9801\n",
      "70 \t16    \t5.47219\t4.79426\t0.31111 \t20.9801\n",
      "INFO:__main__:71 \t23    \t7.90359\t7.97989\t0.31111 \t54.6821\n",
      "71 \t23    \t7.90359\t7.97989\t0.31111 \t54.6821\n",
      "INFO:__main__:72 \t20    \t6.73382\t4.30232\t0.31111 \t19.6368\n",
      "72 \t20    \t6.73382\t4.30232\t0.31111 \t19.6368\n",
      "INFO:__main__:73 \t20    \t5.50908\t5.22659\t0.31111 \t29.6094\n",
      "73 \t20    \t5.50908\t5.22659\t0.31111 \t29.6094\n",
      "INFO:__main__:74 \t15    \t5.58987\t3.63602\t0.31111 \t16.3225\n",
      "74 \t15    \t5.58987\t3.63602\t0.31111 \t16.3225\n",
      "INFO:__main__:75 \t14    \t4.78258\t3.78766\t0.31111 \t20.1395\n",
      "75 \t14    \t4.78258\t3.78766\t0.31111 \t20.1395\n",
      "INFO:__main__:76 \t14    \t6.45573\t8.77566\t0.31111 \t68.0829\n",
      "76 \t14    \t6.45573\t8.77566\t0.31111 \t68.0829\n",
      "INFO:__main__:77 \t21    \t5.21531\t4.05601\t0.31111 \t21.6954\n",
      "77 \t21    \t5.21531\t4.05601\t0.31111 \t21.6954\n",
      "INFO:__main__:78 \t21    \t6.68578\t5.50079\t0.31111 \t22.6923\n",
      "78 \t21    \t6.68578\t5.50079\t0.31111 \t22.6923\n",
      "INFO:__main__:79 \t13    \t9.72943\t5.84763\t0.31111 \t22.6923\n",
      "79 \t13    \t9.72943\t5.84763\t0.31111 \t22.6923\n",
      "INFO:__main__:80 \t11    \t5.5547 \t3.86261\t0.31111 \t18.792 \n",
      "80 \t11    \t5.5547 \t3.86261\t0.31111 \t18.792 \n",
      "INFO:__main__:81 \t16    \t7.41794\t5.54662\t0.31111 \t19.6954\n",
      "81 \t16    \t7.41794\t5.54662\t0.31111 \t19.6954\n",
      "INFO:__main__:82 \t17    \t7.66646\t6.70516\t0.31111 \t40.3407\n",
      "82 \t17    \t7.66646\t6.70516\t0.31111 \t40.3407\n"
=======
      "INFO:__main__:2  \t19    \t1696.78\t3403.59\t8.97848\t9000\n",
      "2  \t19    \t1696.78\t3403.59\t8.97848\t9000\n",
      "INFO:__main__:3  \t24    \t200.686\t915.974\t8.97848\t9000\n",
      "3  \t24    \t200.686\t915.974\t8.97848\t9000\n",
      "INFO:__main__:4  \t24    \t22.8813\t26.647 \t4.023  \t188.638\n",
      "4  \t24    \t22.8813\t26.647 \t4.023  \t188.638\n",
      "INFO:__main__:5  \t24    \t134.729\t888.433\t4.023  \t9000   \n",
      "5  \t24    \t134.729\t888.433\t4.023  \t9000   \n",
      "INFO:__main__:6  \t27    \t19.622 \t17.2442\t3.36794\t100.916\n",
      "6  \t27    \t19.622 \t17.2442\t3.36794\t100.916\n",
      "INFO:__main__:7  \t32    \t59.0473\t242.102\t3.36794\t1933.88\n",
      "7  \t32    \t59.0473\t242.102\t3.36794\t1933.88\n",
      "INFO:__main__:8  \t17    \t240.795\t968.406\t3.36794\t9000   \n",
      "8  \t17    \t240.795\t968.406\t3.36794\t9000   \n",
      "INFO:__main__:9  \t23    \t17.637 \t19.8645\t3.36794\t155.591\n",
      "9  \t23    \t17.637 \t19.8645\t3.36794\t155.591\n",
      "INFO:__main__:10 \t21    \t46.7282\t139.632\t1.65962\t1397.28\n",
      "10 \t21    \t46.7282\t139.632\t1.65962\t1397.28\n",
      "INFO:__main__:11 \t21    \t30.0006\t33.3149\t1.65962\t185.231\n",
      "11 \t21    \t30.0006\t33.3149\t1.65962\t185.231\n",
      "INFO:__main__:12 \t23    \t122.987\t888.444\t1.65962\t9000   \n",
      "12 \t23    \t122.987\t888.444\t1.65962\t9000   \n",
      "INFO:__main__:13 \t19    \t8.80387\t9.78907\t1.65962\t51.8041\n",
      "13 \t19    \t8.80387\t9.78907\t1.65962\t51.8041\n",
      "INFO:__main__:14 \t25    \t16.1489\t12.3344\t1.65962\t51.9325\n",
      "14 \t25    \t16.1489\t12.3344\t1.65962\t51.9325\n",
      "INFO:__main__:15 \t26    \t20.0964\t16.7001\t1.65962\t96.4355\n",
      "15 \t26    \t20.0964\t16.7001\t1.65962\t96.4355\n",
      "INFO:__main__:16 \t25    \t105.676\t889.495\t1.65962\t9000   \n",
      "16 \t25    \t105.676\t889.495\t1.65962\t9000   \n",
      "INFO:__main__:17 \t19    \t9.11809\t8.13685\t1.65962\t57.6859\n",
      "17 \t19    \t9.11809\t8.13685\t1.65962\t57.6859\n",
      "INFO:__main__:18 \t30    \t13.9646\t12.666 \t1.65962\t61.561 \n",
      "18 \t30    \t13.9646\t12.666 \t1.65962\t61.561 \n",
      "INFO:__main__:19 \t29    \t20.1252\t14.8279\t0.463462\t73.568 \n",
      "19 \t29    \t20.1252\t14.8279\t0.463462\t73.568 \n",
      "INFO:__main__:20 \t27    \t28.9629\t111.78 \t0.463462\t1137.64\n",
      "20 \t27    \t28.9629\t111.78 \t0.463462\t1137.64\n",
      "INFO:__main__:21 \t19    \t15.3477\t14.9005\t0.463462\t59.125 \n",
      "21 \t19    \t15.3477\t14.9005\t0.463462\t59.125 \n",
      "INFO:__main__:22 \t25    \t14.0241\t9.97302\t0.463462\t52.7582\n",
      "22 \t25    \t14.0241\t9.97302\t0.463462\t52.7582\n",
      "INFO:__main__:23 \t31    \t192.317\t1251.92\t0.463462\t9000   \n",
      "23 \t31    \t192.317\t1251.92\t0.463462\t9000   \n",
      "INFO:__main__:24 \t20    \t6.94555\t7.21187\t0.463462\t41.2771\n",
      "24 \t20    \t6.94555\t7.21187\t0.463462\t41.2771\n",
      "INFO:__main__:25 \t24    \t13.0348\t13.5008\t0.463462\t79.7128\n",
      "25 \t24    \t13.0348\t13.5008\t0.463462\t79.7128\n",
      "INFO:__main__:26 \t18    \t17.3822\t13.9359\t0.463462\t70.4439\n",
      "26 \t18    \t17.3822\t13.9359\t0.463462\t70.4439\n",
      "INFO:__main__:27 \t20    \t15.4781\t12.4657\t0.463462\t57.7527\n",
      "27 \t20    \t15.4781\t12.4657\t0.463462\t57.7527\n"
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
     ]
    }
   ],
   "source": [
    "no_list = pickle.load(open(\"too_rippled_b.p\",\"rb\"))\n",
    "yes_list\n",
    "#delete_list = ['AP_duration_half_width_change_3.0x','AHP_depth_1.5x','AP_amplitude_diff_1.5x','AP2_AP1_diff_1.5x','AP_amplitude_change_1.5x','AP_duration_half_width_change_3.0x','time_to_second_spike_1.5x','time_constant_1.5x','max_amp_difference_1.5x','inv_fourth_ISI_1.5x','AP_duration_half_width_1.5x','time_to_first_spike_1.5x']\n",
    "\n",
    "objectives2 = []\n",
    "for cnt,tt in enumerate(nu_tests):\n",
    "    feature_name = '%s' % (tt.name)\n",
    "    if (feature_name not in no_list) and (feature_name in yes_list):\n",
    "        if feature_name != \"time_constant_1.5x\" and feature_name != \"RheobaseTest\":\n",
    "            ft = NUFeatureAllenMultiSpike(tt,model,cnt,target,check_list,spike_obs,print_stuff=True)\n",
    "            objective = ephys.objectives.SingletonObjective(\n",
    "                feature_name,\n",
    "                ft)\n",
    "            objectives2.append(objective)\n",
    "#for tt in aug_nu_tests:            \n",
<<<<<<< HEAD
    "'''\n",
=======
    "\n",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "tt = aug_nu_tests[0]\n",
    "print(tt.name)\n",
    "ft = NUFeatureAllenMultiSpike(tt,model,cnt,target,check_list,spike_obs,print_stuff=True)\n",
    "objective = ephys.objectives.SingletonObjective(    \n",
    "    \"RheobaseTest\",\n",
    "    ft)\n",
    "objectives2.append(objective)\n",
<<<<<<< HEAD
    "'''\n",
=======
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "score_calc2 = ephys.objectivescalculators.ObjectivesCalculator(objectives2) \n",
    "\n",
    "        \n",
    "#score_calc2 = ephys.objectivescalculators.ObjectivesCalculator(objectives2) \n",
    "\n",
    "MODEL_PARAMS[\"IZHI\"]\n",
    "cell_evaluator2 = ephys.evaluators.CellEvaluator(\n",
    "        cell_model=simple_cell,\n",
    "        param_names=list(MODEL_PARAMS[\"IZHI\"].keys()),\n",
    "        fitness_protocols={twostep_protocol.name: twostep_protocol},\n",
    "        fitness_calculator=score_calc2,\n",
    "        sim='euler')\n",
    "simple_cell.params_by_names(MODEL_PARAMS[\"IZHI\"].keys())\n",
    "\n",
    "simple_cell.params;\n",
    "\n",
    "\n",
    "MODEL_PARAMS[\"IZHI\"]\n",
    "cell_evaluator2 = ephys.evaluators.CellEvaluator(\n",
    "        cell_model=simple_cell,\n",
    "        param_names=list(MODEL_PARAMS[\"IZHI\"].keys()),\n",
    "        fitness_protocols={twostep_protocol.name: twostep_protocol},\n",
    "        fitness_calculator=score_calc2,\n",
    "        sim='euler')\n",
    "\n",
    "MU =50\n",
    "\n",
<<<<<<< HEAD
    "#optimisation = bpop.optimisations.DEAPOptimisation(\n",
    "#        evaluator=cell_evaluator2,\n",
    "#        offspring_size = MU,\n",
    "#        map_function = dask_map_function,\n",
    "#        selector_name='IBEA',mutpb=0.15,cxpb=0.35)\n",
=======
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "optimisation = bpop.optimisations.DEAPOptimisation(\n",
    "        evaluator=cell_evaluator2,\n",
    "        offspring_size = MU,\n",
    "        map_function = dask_map_function,\n",
<<<<<<< HEAD
    "        selector_name='IBEA',mutpb=0.05,cxpb=0.2)#,seeded_pop=[cp['final_pop'],cp['hall_of_fame']])\n",
    "final_pop, hall_of_fame, logs, hist = optimisation.run(max_ngen=1100)\n",
=======
    "        selector_name='IBEA',mutpb=0.15,cxpb=0.35)#,seeded_pop=[cp['final_pop'],cp['hall_of_fame']])\n",
    "final_pop, hall_of_fame, logs, hist = optimisation.run(max_ngen=100)\n",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "\n",
    "\n",
    "gen_numbers = logs.select('gen')\n",
    "min_fitness = logs.select('min')\n",
    "max_fitness = logs.select('max')\n",
    "avg_fitness = logs.select('avg')\n",
    "plt.plot(gen_numbers, max_fitness, label='max fitness')\n",
    "plt.plot(gen_numbers, avg_fitness, label='avg fitness')\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
    "\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
    "plt.xlabel('generation #')\n",
    "plt.ylabel('score (# std)')\n",
    "plt.legend()\n",
    "plt.xlim(min(gen_numbers) - 1, max(gen_numbers) + 1) \n",
<<<<<<< HEAD
    "#plt.ylim(0.9*min(min_fitness), 1.1 * max(min_fitness)) \n",
=======
    "plt.ylim(0.9*min(min_fitness), 1.1 * max(min_fitness)) \n",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "#9071000.0\n",
    "#4144000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,j in zip(final_pop[-1].fitness.values,objectives2):\n",
    "#    if i>10:\n",
    "#        print(i,j.name)\n",
    "\n",
    "plt.plot(gen_numbers, max_fitness, label='max fitness')\n",
    "plt.plot(gen_numbers, avg_fitness, label='avg fitness')\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
    "\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
<<<<<<< HEAD
    "plt.semilogy()\n",
=======
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "plt.xlabel('generation #')\n",
    "plt.ylabel('score (# std)')\n",
    "plt.legend()\n",
    "plt.xlim(min(gen_numbers) - 1, max(gen_numbers) + 1) \n",
<<<<<<< HEAD
    "#plt.ylim(0.9*min(min_fitness), 1.1 * max(min_fitness)) \n",
=======
    "plt.ylim(0.9*min(min_fitness), 1.1 * max(min_fitness)) \n",
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_ind = hall_of_fame[0]\n",
    "best_ind_dict = cell_evaluator2.param_dict(best_ind)\n",
    "model = cell_evaluator2.cell_model\n",
    "cell_evaluator2.param_dict(best_ind)\n",
    "\n",
    "model.attrs = {str(k):float(v) for k,v in cell_evaluator2.param_dict(best_ind).items()}\n",
    "opt = model.model_to_dtc()\n",
    "opt.attrs = {str(k):float(v) for k,v in cell_evaluator2.param_dict(best_ind).items()}\n",
    "target\n",
    "\n",
    "from neuronunit.optimisation.optimization_management import dtc_to_rheo, inject_and_plot_model30,check_bin_vm30,check_bin_vm15\n",
    "\n",
    "vm301,vm151,_,_,target = inject_and_plot_model30(target)\n",
    "vm302,vm152,_,_,opt = inject_and_plot_model30(opt)\n",
    "check_bin_vm30(target,opt)\n",
    "check_bin_vm15(target,opt)\n",
    "for i,j in zip(best_ind.fitness.values,objectives2):\n",
    "   print(i,j.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "check_bin_vm30(opt,opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_bin_vm30(target,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "print([o.name for o in objectives2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.rheobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.rheobase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def hof_to_euclid\n",
    "def hof_to_euclid_4(hof,MODEL_PARAMS,target,ranges=True):\n",
    "    lengths = {}\n",
    "    tv = 1\n",
    "    cnt = 0\n",
    "    constellation0 = hof[0]\n",
    "    constellation1 = hof[1]\n",
    "    subset = list(MODEL_PARAMS.keys())\n",
    "    tg = target.dtc_to_gene(subset_params=subset)\n",
    "    if len(MODEL_PARAMS)==1:\n",
    "        \n",
    "        ax = plt.subplot()\n",
    "        for k,v in MODEL_PARAMS.items():\n",
    "            lengths[k] = np.abs(np.abs(v[1])-np.abs(v[0]))\n",
    "\n",
    "            x = sorted([h[cnt] for h in hof])\n",
    "            y = [np.sum(h.fitness.values) for h in hof]\n",
    "            tgene = tg[cnt]\n",
    "            yg = 0\n",
    "        plt.plot(x,y)\n",
    "            \n",
    "\n",
    "        ax.scatter(x, y, c='b', marker='o',label='samples')\n",
    "        ax.scatter(tgene, yg, c='r', marker='*',label='target')\n",
    "        if ranges:\n",
    "            ax.set_xlim(np.min(hof),np.max(hof))\n",
    "            ax.set_xlabel(k)\n",
    "        #ax.plot(x,y)\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "#def animate(i):\n",
    "\n",
    "def movie(hof,MODEL_PARAMS,target,max_height):\n",
    "    lengths = {}\n",
    "    tv = 1\n",
    "    cnt = 0\n",
    "    subset = list(MODEL_PARAMS.keys())\n",
    "    tg = target.dtc_to_gene(subset_params=subset)\n",
    "    if len(MODEL_PARAMS)==1:\n",
    "        plt.clf()\n",
    "        ax = plt.subplot()\n",
    "\n",
    "        x =  hof[cnt] \n",
    "        y = sum(hof.fitness.values)\n",
    "        tgene = tg[cnt]\n",
    "        yg = 0\n",
    "\n",
    "        ax.scatter(x, y, c='b', marker='o',label='samples')\n",
    "        #ax.plot(x,y)\n",
    "        ax.scatter(tgene, yg, c='r', marker='*',label='target')\n",
    "        ax.set_xlim(np.min(MODEL_PARAMS[subset[0]]),np.max(MODEL_PARAMS[subset[0]]))\n",
    "        ax.set_ylim(0,max_height)\n",
    "\n",
    "        ax.set_xlabel(k)\n",
    "\n",
    "        return ax,plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def threshold_detection2(signal, threshold=0.0, sign='above'):\n",
    "    \"\"\"\n",
    "    Returns the times when the analog signal crosses a threshold.\n",
    "    Usually used for extracting spike times from a membrane potential. \n",
    "    Adapted from version in NeuroTools.   \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : neo AnalogSignal object\n",
    "        'signal' is an analog signal.\n",
    "    threshold : A quantity, e.g. in mV  \n",
    "        'threshold' contains a value that must be reached \n",
    "        for an event to be detected.\n",
    "    sign : 'above' or 'below'\n",
    "        'sign' determines whether to count thresholding crossings\n",
    "        that cross above or below the threshold.  \n",
    "    format : None or 'raw'\n",
    "        Whether to return as SpikeTrain (None) \n",
    "        or as a plain array of times ('raw').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result_st : neo SpikeTrain object\n",
    "        'result_st' contains the spike times of each of the events (spikes)\n",
    "        extracted from the signal.  \n",
    "    \"\"\"\n",
    "\n",
    "    assert threshold is not None, \"A threshold must be provided\"\n",
    "\n",
    "    if sign is 'above':\n",
    "        cutout = np.where(signal > threshold)[0]\n",
    "    elif sign in 'below':\n",
    "        cutout = np.where(signal < threshold)[0]\n",
    "\n",
    "    if len(cutout) <= 0:\n",
    "        events = np.zeros(0)\n",
    "        return np.array([0])\n",
    "    else:\n",
    "        take = np.where(np.diff(cutout)>1)[0]+1\n",
    "        take = np.append(0,take)\n",
    "        return take\n",
    "        #time = signal.times\n",
    "        #events = time[cutout][take]\n",
    "   # return len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_MODEL_PARAMS = copy.copy(MODEL_PARAMS['IZHI'])\n",
    "\n",
    "\n",
    "sub_MODEL_PARAMS\n",
    "hof_to_euclid_4(hall_of_fame,sub_MODEL_PARAMS,target)\n",
    "sub_MODEL_PARAMS\n",
    "hof_to_euclid_4(list(hist.genealogy_history.values()),sub_MODEL_PARAMS,target)#,ranges=small)\n",
    "subset = list(sub_MODEL_PARAMS.keys())\n",
    "tg = target.dtc_to_gene(subset_params=subset)\n",
    "tg\n",
    "MODEL_PARAMS['IZHI']\n",
    "tg\n",
    "\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "#untractable=[]\n",
    "#tractable=[]\n",
    "def ripple_detection(hof,MODEL_PARAMS,target,objectives2,max_height, show_hard=True):\n",
    "    lengths = {}\n",
    "    tv = 1\n",
    "    cnt = 0\n",
    "    subset = list(MODEL_PARAMS.keys())\n",
    "    tg = target.dtc_to_gene(subset_params=subset)\n",
    "    good_for_opt = []\n",
    "    know_for_future_opt = []\n",
    "    for i,f in enumerate(hof[0].fitness.values):    \n",
    "        plt.clf()\n",
    "        lengths[k] = np.abs(np.abs(v[1])-np.abs(v[0]))\n",
    "        \n",
    "        # debug change this 200.\n",
    "        x_plot = np.linspace(np.abs(v[1]),np.abs(v[0]),200)\n",
    "\n",
    "        X_plot = x_plot[:, np.newaxis]\n",
    "\n",
    "        hof_x = sorted([ h for h in hof ])\n",
    "\n",
    "        y = [ h.fitness.values[i] for h in hof_x ] \n",
    "        tgene = tg[cnt]\n",
    "        yg = 0\n",
    "        model = make_pipeline(PolynomialFeatures(6), Ridge())\n",
    "\n",
    "        model.fit(hof_x, y)\n",
    "        model.predict(X_plot)\n",
    "        y_plot = model.predict(X_plot)\n",
    "        y_thresh = np.mean(y_plot)\n",
    "        n_crosses = threshold_detection2(y, threshold=y_thresh, sign='above')\n",
    "        \n",
    "        if n_crosses is not None:# is not None:\n",
    "            untractable.append(objectives2[i].name)\n",
    "            if show_hard:\n",
    "                if len(n_crosses)>4:\n",
    "                    ax = plt.subplot()\n",
    "                    plt.title(objectives2[i].name)\n",
    "\n",
    "\n",
    "                    plt.plot(hof_x,y)\n",
    "                    ax.scatter(hof_x, y, c='b', marker='o',label='samples')\n",
    "                    ax.scatter(tgene, yg, c='r', marker='*',label='target')\n",
    "                    ax.set_xlim(np.min(hof),np.max(hof))\n",
    "                    ax.set_xlabel(k)\n",
    "\n",
    "                    plt.plot(X_plot, y_plot)\n",
    "                    ax.legend()\n",
    "                    plt.show()\n",
    "                    know_for_future_opt.append(objectives2[i].name)\n",
    "                \n",
    "        if len(n_crosses)<5:\n",
    "            tractable.append(tractable)\n",
    "            if not show_hard:\n",
    "                ax = plt.subplot()\n",
    "\n",
    "                plt.title(objectives2[i].name)\n",
    "\n",
    "\n",
    "                plt.plot(hof_x,y)\n",
    "                ax.scatter(hof_x, y, c='b', marker='o',label='samples')\n",
    "                ax.scatter(tgene, yg, c='r', marker='*',label='target')\n",
    "                ax.set_xlim(np.min(hof),np.max(hof))\n",
    "                ax.set_xlabel(k)\n",
    "\n",
    "                plt.plot(X_plot, y_plot)\n",
    "                ax.legend()\n",
    "                plt.show()\n",
    "                good_for_opt.append(objectives2[i].name)\n",
    "\n",
    "    if show_hard:\n",
    "        pickle.dump(know_for_future_opt,open('too_rippled.p','wb'))\n",
    "    else:\n",
    "        pickle.dump(good_for_opt,open('tame.p','wb'))\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = list(hist.genealogy_history.values())\n",
    "max_height = np.max([sum(i.fitness.values) for i in pop])\n",
    "\n",
    "ripple_detection(pop,sub_MODEL_PARAMS,target,objectives2,max_height)#,ranges=small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(hist.genealogy_history.values())\n",
    "max_height = np.max([sum(i.fitness.values) for i in temp])\n",
    "ripple_detection(list(hist.genealogy_history.values()),sub_MODEL_PARAMS,target,objectives2,max_height,show_hard=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_collector = []\n",
    "sum_pred_collector = []\n",
    "\n",
    "\n",
    "model.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "opt = model.model_to_dtc()\n",
    "opt.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "\n",
    "opt.tests = aug_nu_tests\n",
    "\n",
    "plotxvec = np.linspace(MODEL_PARAMS['IZHI']['a'][0],MODEL_PARAMS['IZHI']['a'][1],20)\n",
    "for a in plotxvec:\n",
    "    opt.attrs['a'] = a\n",
    "    opt.self_evaluate()\n",
    "    for t in opt.tests:\n",
    "        try:\n",
    "            t.prediction['value'] = t.prediction['mean']\n",
    "        except:\n",
    "            pass\n",
    "    values = [test.prediction['value'] for test in opt.tests]\n",
    "    pred_collector.append(values)\n",
    "    sum_pred_collector.append(np.sum([values]))\n",
    "#plt.title('sum of errors')\n",
    "#plt.plot(plotxvec,sum_pred_collector)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spikes2thresholds_debug(spike_waveforms):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "     spike_waveforms: Spike waveforms, e.g. from get_spike_waveforms().\n",
    "        neo.core.AnalogSignal\n",
    "    OUT:\n",
    "     1D numpy array of spike thresholds, specifically the membrane potential\n",
    "     at which 1/10 the maximum slope is reached.\n",
    "\n",
    "    If the derivative contains NaNs, probably because vm contains NaNs\n",
    "    Return an empty list with the appropriate units\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        n_spikes = spike_waveforms.shape[1]\n",
    "    except:\n",
    "        return None\n",
    "        #return thresholds * spike_waveforms.units\n",
    "\n",
    "\n",
    "    thresholds = []\n",
    "    if n_spikes > 1:\n",
    "        # good to know can handle multispikeing\n",
    "        pass\n",
    "    for i in range(n_spikes):\n",
    "        s = spike_waveforms[:, i].squeeze()\n",
    "        s = np.array(s)\n",
    "        dvdt = np.diff(s)\n",
    "        for j in dvdt:\n",
    "            if math.isnan(j):\n",
    "                return thresholds * spike_waveforms.units\n",
    "        try:\n",
    "            trigger = dvdt.max()/10.0\n",
    "        except:\n",
    "            return None\n",
    "            # try this next.\n",
    "            # return thresholds * spike_waveforms.units\n",
    "\n",
    "        try:\n",
    "            x_loc = np.where(dvdt >= trigger)[0][0]\n",
    "            \n",
    "            thresh = (s[x_loc]+s[x_loc+1])/2\n",
    "            \n",
    "        except:\n",
    "            thresh = None\n",
    "        thresholds.append(thresh)\n",
    "        plt.plot(s.times,s.magnitude)        \n",
    "        plt.scatter(x_loc,thresh)\n",
    "        plt.show()\n",
    "        #plt.savefig(\"debug_threshold.png\")\n",
    "        \n",
    "    return thresholds * spike_waveforms.units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_ind = hall_of_fame[0]\n",
    "best_ind_dict = cell_evaluator.param_dict(best_ind)\n",
    "model = cell_evaluator.cell_model\n",
    "cell_evaluator.param_dict(best_ind)\n",
    "model.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "opt = model.model_to_dtc()\n",
    "opt.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "opt = opt.attrs\n",
    "\n",
    "#opt.tests = aug_nu_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do measurements\n",
    "from the standard suite vary \n",
    "with changes in 'a'?\n",
    "\n",
    "Note these are not scores or like in the above tests, but simply how do measurements change with changes in 'a'\n",
    "\n",
    "In this we see sometimes 'a' causes ripples in very basic measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [test.name for test in opt.tests]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def smoothTriangle(data, degree):\n",
    "    triangle=np.concatenate((np.arange(degree + 1), np.arange(degree)[::-1])) # up then down\n",
    "    smoothed=[]\n",
    "\n",
    "    for i in range(degree, len(data) - degree * 2):\n",
    "        point=data[i:i + len(triangle)] * triangle\n",
    "        smoothed.append(np.sum(point)/np.sum(triangle))\n",
    "    # Handle boundaries\n",
    "    smoothed=[smoothed[0]]*int(degree + degree/2) + smoothed\n",
    "    while len(smoothed) < len(data):\n",
    "        smoothed.append(smoothed[-1])\n",
    "    return smoothed\n",
    "\n",
    "for i in range(0,len(pred_collector[0])):\n",
    "    plt.clf()\n",
    "    plt.title(names[i])\n",
    "    measurement = [val[i] for val in pred_collector]\n",
    "    plt.plot(plotxvec,measurement)\n",
    "    \n",
    "    #from scipy.interpolate import spline\n",
    "    #from scipy.interpolate import interp1d\n",
    "\n",
    "   # xnew = np.linspace(plotxvec[0],plotxvec[1],300) #300 represents number of points to make between T.min and T.max\n",
    "\n",
    "    #measurement_smooth = interp1d(T,measurement,xnew)\n",
    "\n",
    "    \n",
    "    #x = np.linspace(0, 10, num=11, endpoint=True)\n",
    "    #y = np.cos(-x**2/9.0)\n",
    "    #f1 = interp1d(plotxvec, measurement, kind='nearest')\n",
    "    #f2 = interp1d(plotxvec, measurement, kind='zero')\n",
    "    #f3 = interp1d(plotxvec, measurement, kind='quadratic')\n",
    "\n",
    "    \n",
    "    plt.plot(plotxvec,smoothTriangle(measurement,14))\n",
    "    #plt.plot(plotxvec,f2)\n",
    "    #plt.plot(plotxvec,f3)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {k:np.mean(v) for k,v in MODEL_PARAMS[\"IZHI\"].items()}\n",
    "from neuronunit.capabilities.spike_functions import get_spike_waveforms, spikes2widths, spikes2thresholds\n",
    "from quantities import ms\n",
    "from neuronunit.tests.base import AMPL, DELAY, DURATION\n",
    "from neuronunit.optimisation.data_transport_container import DataTC\n",
    "for slider_value in np.linspace(0.01, 0.1, 100):\n",
    "  #print(slider_value)\n",
    "\n",
    "  dtc = DataTC(backend=\"IZHI\",attrs=attrs)\n",
    "  dtc.attrs['a'] = slider_value\n",
    "  dtc = dtc_to_rheo(dtc)\n",
    "  model = dtc.dtc_to_model()\n",
    "  model.attrs = model._backend.default_attrs\n",
    "  model.attrs.update(dtc.attrs)\n",
    "  #print(model.attrs)\n",
    "  uc = {'amplitude':dtc.rheobase,'duration':DURATION,'delay':DELAY}\n",
    "  model._backend.inject_square_current(uc)\n",
    "  vm = model.get_membrane_potential()\n",
    "  #print(np.max(vm)-np.min(vm))\n",
    "  snippets1 = get_spike_waveforms(vm)#,width=20*ms)\n",
    "  spikes2thresholds_debug(snippets1)\n",
    "  #plt.plot(snippets1.times,snippets1.magnitude) \n",
    "  plt.plot(vm.times,vm.magnitude) \n",
    "  #snippets1 = get_spike_waveforms(vm,width=10*ms)\n",
    "  #print(spikes2widths(snippets1)[0])\n",
    "  print(np.max(vm)-spikes2thresholds(snippets1)[0])\n",
    "  #plt.plot(snippets1.times,snippets1.magnitude) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {k:np.mean(v) for k,v in MODEL_PARAMS[\"IZHI\"].items()}\n",
    "from neuronunit.capabilities.spike_functions import get_spike_waveforms, spikes2widths, spikes2thresholds\n",
    "from quantities import ms\n",
    "from neuronunit.tests.base import AMPL, DELAY, DURATION\n",
    "from neuronunit.optimisation.data_transport_container import DataTC\n",
    "for slider_value in np.linspace(0.01, 0.1, 100):\n",
    "  #print(slider_value)\n",
    "\n",
    "  dtc = DataTC(backend=\"IZHI\",attrs=attrs)\n",
    "  dtc.attrs['a'] = slider_value\n",
    "  dtc = dtc_to_rheo(dtc)\n",
    "  model = dtc.dtc_to_model()\n",
    "  model.attrs = model._backend.default_attrs\n",
    "  model.attrs.update(dtc.attrs)\n",
    "  #print(model.attrs)\n",
    "  uc = {'amplitude':dtc.rheobase*1.5,'duration':DURATION,'delay':DELAY}\n",
    "  model._backend.inject_square_current(uc)\n",
    "  vm = model.get_membrane_potential()\n",
    "  #print(np.max(vm)-np.min(vm))\n",
    "  #snippets1 = get_spike_waveforms(vm)#,width=20*ms)\n",
    "  plt.clf()\n",
    "  #plt.plot(snippets1.times,snippets1.magnitude) \n",
    "  plt.plot(vm.times,vm.magnitude) \n",
    "  #snippets1 = get_spike_waveforms(vm,width=10*ms)\n",
    "  #print(spikes2widths(snippets1)[0])\n",
    "  #print(spikes2thresholds(snippets1)[0])\n",
    "  #plt.plot(snippets1.times,snippets1.magnitude) \n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  plt.clf()\n",
    "  uc = {'amplitude':dtc.rheobase*3.0,'duration':DURATION,'delay':DELAY}\n",
    "  model._backend.inject_square_current(uc)\n",
    "  vm = model.get_membrane_potential()\n",
    "    \n",
    "  #plt.plot(snippets1.times,snippets1.magnitude) \n",
    "  #plt.plot(vm.times,vm.magnitude) \n",
    "  snippets1 = get_spike_waveforms(vm,width=10*ms)\n",
    "  print(spikes2widths(snippets1)[0])\n",
    "  print(spikes2thresholds(snippets1)[0])\n",
    "  #plt.plot(snippets1.times,snippets1.magnitude) \n",
    "\n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "#measurement = [float(val[0])-155 for val in pred_collector]\n",
    "#plt.plot(plotxvec,measurement)\n",
    "#plt.semilogy()\n",
    "plotxvec = np.linspace(MODEL_PARAMS['IZHI']['a'][0],MODEL_PARAMS['IZHI']['a'][1]*2,200)\n",
    "\n",
    "measurement = [val[-1] for val in pred_collector]\n",
    "plt.plot(plotxvec,measurement)\n",
    "\n",
    "measurement = [float(val[-2])-75 for val in pred_collector]\n",
    "plt.plot(plotxvec,measurement)\n",
    "measurement = [float(val[-3]) for val in pred_collector]\n",
    "plt.plot(plotxvec,measurement)\n",
    "\n",
    "#plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = opt.dtc_to_model()\n",
    "plotyvec = []\n",
    "plotxvec = np.linspace(MODEL_PARAMS['IZHI']['a'][0],MODEL_PARAMS['IZHI']['a'][1]*2,100)\n",
    "for a in plotxvec:\n",
    "    m.attrs['a'] = a\n",
    "    #print(opt.tests[-2].params)\n",
    "\n",
    "    plotyvec.append(opt.tests[-2].generate_prediction(m)['value'])\n",
    "plt.plot(plotxvec,plotyvec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.optimization_management import inject_and_plot_model, dtc_to_rheo\n",
    "plotxvec = np.linspace(MODEL_PARAMS['IZHI']['a'][0],MODEL_PARAMS['IZHI']['a'][1],100)\n",
    "for a in plotxvec:\n",
    "    opt.attrs['a'] = a\n",
    "    opt = dtc_to_rheo(opt)\n",
    "    opt.self_evaluate()\n",
    "    try:\n",
    "        out = inject_and_plot_model(opt,plotly=False)\n",
    "        print(out)\n",
    "        #vm.show()\n",
    "\n",
    "    #except:\n",
    "        plt = inject_and_plot_model(opt,plotly=False)\n",
    "        print(opt.rheobase)\n",
    "    #for t in opt.tests:\n",
    "    #    try:\n",
    "    #        t.prediction['value'] = t.prediction['mean']\n",
    "    #    except:\n",
    "    #        pass\n",
    "    #values = [test.prediction['value'] for test in opt.tests]\n",
    "    #pred_collector.append(values)\n",
    "    #sum_pred_collector.append(np.sum([values]))\n",
    "#plt.title('sum of errors')\n",
    "#plt.plot(plotxvec,sum_pred_collector)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotxvec = np.linspace(MODEL_PARAMS['IZHI']['a'][0],MODEL_PARAMS['IZHI']['a'][1],100)\n",
    "for a in plotxvec:\n",
    "    opt.attrs['a'] = a\n",
    "    opt = dtc_to_rheo(opt)\n",
    "    opt.self_evaluate()\n",
    "    vm,plt = inject_and_plot_model(opt)\n",
    "    plt.show()\n",
    "    for t in opt.tests:\n",
    "        try:\n",
    "            t.prediction['value'] = t.prediction['mean']\n",
    "        except:\n",
    "            pass\n",
    "    values = [test.prediction['value'] for test in opt.tests]\n",
    "    pred_collector.append(values)\n",
    "    sum_pred_collector.append(np.sum([values]))\n",
    "plt.title('sum of errors')\n",
    "plt.plot(plotxvec,sum_pred_collector)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# are changes in b just as dramatic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from neuronunit.optimisation.model_parameters import MODEL_PARAMS as mp\n",
    "print(mp['IZHI'])\n",
    "pred_collector = []\n",
    "sum_pred_collector = []\n",
    "\n",
    "plotxvec = np.linspace(-2,15,100)\n",
    "opt.attrs['a'] = np.mean(MODEL_PARAMS['IZHI']['a'])\n",
    "for b in plotxvec:\n",
    "    \n",
    "    opt.attrs['b'] = b\n",
    "    opt.self_evaluate()\n",
    "    for t in opt.tests:\n",
    "        try:\n",
    "            t.prediction['value'] = t.prediction['mean']\n",
    "        except:\n",
    "            pass\n",
    "    values = [test.prediction['value'] for test in opt.tests]\n",
    "    pred_collector.append(values)\n",
    "    sum_pred_collector.append(np.sum([values]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.title('sum of errors')\n",
    "#plt.plot(plotxvec,sum_pred_collector)\n",
    "#plt.show()\n",
    "\n",
    "names = [test.name for test in opt.tests]\n",
    "\n",
    "for i in range(0,len(pred_collector[0])):\n",
    "    plt.clf()\n",
    "    plt.title(names[i])\n",
    "    plt.plot(plotxvec,[val[i] for val in pred_collector])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And **c**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from neuronunit.optimisation.model_parameters import MODEL_PARAMS as mp\n",
    "print(mp['IZHI'])\n",
    "pred_collector = []\n",
    "sum_pred_collector = []\n",
    "\n",
    "opt.attrs['a'] = np.mean(MODEL_PARAMS['IZHI']['a'])\n",
    "opt.attrs['b'] = np.mean(plotxvec)\n",
    "plotxvec = np.linspace(-60,-40,100)\n",
    " \n",
    "for c in plotxvec:\n",
    "    \n",
    "    opt.attrs['c'] = c\n",
    "    opt.self_evaluate()\n",
    "    for t in opt.tests:\n",
    "        try:\n",
    "            t.prediction['value'] = t.prediction['mean']\n",
    "        except:\n",
    "            pass\n",
    "    values = [test.prediction['value'] for test in opt.tests if test.prediction['value'] is not None]\n",
    "    pred_collector.append(values)\n",
    "    sum_pred_collector.append(np.sum([values]))\n",
    "\n",
    "names = [test.name for test in opt.tests]\n",
    "\n",
    "for i in range(0,len(pred_collector[0])):\n",
    "    plt.clf()\n",
    "    plt.title(names[i])\n",
    "    plt.plot(plotxvec,[val[i] for val in pred_collector])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And **C**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS as mp\n",
    "print(mp['IZHI'])\n",
    "pred_collector = []\n",
    "sum_pred_collector = []\n",
    "\n",
    "#opt.attrs['a'] = np.mean(MODEL_PARAMS['IZHI']['a'])\n",
    "#opt.attrs['b'] = np.mean(plotxvec)\n",
    "opt.attrs['c'] = np.mean(plotxvec)\n",
    "\n",
    "plotxvec = np.linspace(50,200,100)\n",
    " \n",
    "for C in plotxvec:\n",
    "    \n",
    "    opt.attrs['C'] = C\n",
    "    opt.self_evaluate()\n",
    "    for t in opt.tests:\n",
    "        try:\n",
    "            t.prediction['value'] = t.prediction['mean']\n",
    "        except:\n",
    "            pass\n",
    "    values = [test.prediction['value'] for test in opt.tests if test.prediction['value'] is not None]\n",
    "    pred_collector.append(values)\n",
    "    sum_pred_collector.append(np.sum([values]))\n",
    "\n",
    "names = [test.name for test in opt.tests]\n",
    "\n",
    "for i in range(0,len(pred_collector[0])):\n",
    "    plt.clf()\n",
    "    plt.title(names[i])\n",
    "    plt.plot(plotxvec,[val[i] for val in pred_collector])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS as mp\n",
    "print(mp['IZHI'])\n",
    "pred_collector = []\n",
    "sum_pred_collector = []\n",
    "\n",
    "#opt.attrs['a'] = np.mean(MODEL_PARAMS['IZHI']['a'])\n",
    "#opt.attrs['b'] = np.mean(plotxvec)\n",
    "opt.attrs['C'] = np.mean(plotxvec)\n",
    "\n",
    "plotxvec = np.linspace(10,150,100)\n",
    " \n",
    "for d in plotxvec:\n",
    "    \n",
    "    opt.attrs['d'] = d\n",
    "    opt.self_evaluate()\n",
    "    for t in opt.tests:\n",
    "        try:\n",
    "            t.prediction['value'] = t.prediction['mean']\n",
    "        except:\n",
    "            pass\n",
    "    values = [test.prediction['value'] for test in opt.tests if test.prediction['value'] is not None]\n",
    "    pred_collector.append(values)\n",
    "    sum_pred_collector.append(np.sum([values]))\n",
    "\n",
    "names = [test.name for test in opt.tests]\n",
    "\n",
    "for i in range(0,len(pred_collector[0])):\n",
    "    plt.clf()\n",
    "    plt.title(names[i])\n",
    "    plt.plot(plotxvec,[val[i] for val in pred_collector])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS as mp\n",
    "print(mp['IZHI'])\n",
    "pred_collector = []\n",
    "sum_pred_collector = []\n",
    "\n",
    "#opt.attrs['a'] = np.mean(MODEL_PARAMS['IZHI']['a'])\n",
    "#opt.attrs['b'] = np.mean(plotxvec)\n",
    "opt.attrs['d'] = np.mean(plotxvec)\n",
    "\n",
    "plotxvec = np.linspace(0.7,1.6,100)\n",
    "#print(plotxvec)\n",
    "for k in plotxvec:\n",
    "    \n",
    "    opt.attrs['k'] = k\n",
    "    #print(opt.attrs)\n",
    "    opt.self_evaluate()\n",
    "    for t in opt.tests:\n",
    "        try:\n",
    "            t.prediction['value'] = t.prediction['mean']\n",
    "        except:\n",
    "            pass\n",
    "    values = [test.prediction['value'] for test in opt.tests if test.prediction['value'] is not None]\n",
    "    pred_collector.append(values)\n",
    "    sum_pred_collector.append(np.sum([values]))\n",
    "\n",
    "names = [test.name for test in opt.tests]\n",
    "\n",
    "for i in range(0,len(pred_collector[0])):\n",
    "    plt.clf()\n",
    "    plt.title(names[i])\n",
    "    plt.plot(plotxvec,[val[i] for val in pred_collector])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "#for i in range(10):\n",
    "\n",
    "temp = list(hist.genealogy_history.values())\n",
    "max_height = np.max([sum(i.fitness.values) for i in temp])\n",
    "#movies = True\n",
    "#if movies:\n",
    "for i,current in enumerate(list(hist.genealogy_history.values())):\n",
    "    max_height\n",
    "    ax,pl = movie(current,sub_MODEL_PARAMS,target,max_height)\n",
    "    pl.title('gene number {0}'.format(i))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "#                               frames=100, interval=20, blit=True)    \n",
    "    \n",
    "#HTML(anim.to_html5_video())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hall_of_fame[1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "MU = 50\n",
    "cp = {}\n",
    "cp['halloffame'] = hall_of_fame\n",
    "cp['population'] = final_pop\n",
    "#seed_pop = cp['halloffame']\n",
    "#cp = pickle.load(open('results_100.p', \"rb\"))\n",
    "\n",
    "#seed_pop.extend(cp['pop'])\n",
    "optimisation = bpop.optimisations.DEAPOptimisation(\n",
    "        evaluator=cell_evaluator2,\n",
    "        offspring_size = MU,\n",
    "        map_function = dask_map_function,\n",
    "        selector_name='IBEA',mutpb=0.1,cxpb=0.2),\n",
    "        #seeded_pop=[cp['halloffame'],cp['population']])\n",
    "final_pop, hall_of_fame, logs, hist = optimisation.run(max_ngen=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The optimisation has return us 4 objects: final population, hall of fame, statistical logs and history. \n",
    "# \n",
    "# The final population contains a list of tuples, with each tuple representing the two parameters of the model\n",
    "\n",
    "\n",
    "#print('Final population: ', final_pop)\n",
    "\n",
    "\n",
    "# The best individual found during the optimisation is the first individual of the hall of fame\n",
    "\n",
    "best_ind = hall_of_fame[0]\n",
    "#print('Best individual: ', best_ind)\n",
    "#print('Fitness values: ', best_ind.fitness.va\n",
    "\n",
    "\n",
    "# We can evaluate this individual and make use of a convenience function of the cell evaluator to return us a dict of the parameters\n",
    "\n",
    "\n",
    "best_ind_dict = cell_evaluator.param_dict(best_ind)\n",
    "#print(cell_evaluator.evaluate_with_dicts(best_ind_dict))\n",
    "\n",
    "\n",
    "model = cell_evaluator.cell_model\n",
    "cell_evaluator.param_dict(best_ind)\n",
    "model.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "\n",
    "\n",
    "\n",
    "opt = model.model_to_dtc()\n",
    "opt.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "\n",
    "check_binary_match(target,opt)\n",
    "inject_and_plot_passive_model(opt,second=target,plotly=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gen_numbers = logs.select('gen')\n",
    "min_fitness = logs.select('min')\n",
    "max_fitness = logs.select('max')\n",
    "avg_fitness = logs.select('avg')\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(gen_numbers, max_fitness, label='max fitness')\n",
    "plt.plot(gen_numbers, avg_fitness, label='avg fitness')\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
    "\n",
    "plt.xlabel('generation #')\n",
    "plt.ylabel('score (# std)')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(min(gen_numbers) - 1, max(gen_numbers) + 1) \n",
    "#plt.ylim(0.9*min(min_fitness), 1.1 * max(min_fitness)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_numbers = logs.select('gen')\n",
    "min_fitness = logs.select('min')\n",
    "max_fitness = logs.select('max')\n",
    "avg_fitness = logs.select('avg')\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "#ax = fig.add_subplot(1,1)\n",
    "\n",
    "plt.plot(gen_numbers, min_fitness, label='min fitness')\n",
    "#ax.semilogy()\n",
    "#ax.set_yscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('generation #')\n",
    "plt.ylabel('score (# std)')\n",
    "plt.legend()\n",
    "plt.xlim(min(gen_numbers) - 1, max(gen_numbers) + 1) \n",
    "#plt.ylim(0.9*min(min_fitness), 1.1 * max(min_fitness)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inject_and_plot_passive_model(opt,second=target,plotly=False)\n",
    "best_ind_dict = cell_evaluator.param_dict(best_ind)\n",
    "objectives = cell_evaluator.evaluate_with_dicts(best_ind_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "best_ind_dict = cell_evaluator.param_dict(best_ind)\n",
    "objectives = cell_evaluator.evaluate_with_dicts(best_ind_dict)\n",
    "\n",
    "model = cell_evaluator.cell_model\n",
    "cell_evaluator.param_dict(best_ind)\n",
    "model.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "\n",
    "opt = model.model_to_dtc()\n",
    "opt.attrs = {str(k):float(v) for k,v in cell_evaluator.param_dict(best_ind).items()}\n",
    "from neuronunit.optimisation.optimization_management import dtc_to_rheo, inject_and_plot_model30,check_bin_vm30,check_bin_vm15\n",
    "opt = dtc_to_rheo(opt)\n",
    "opt.rheobase\n",
    "opt.attrs;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def hof_to_euclid(hof,MODEL_PARAMS,target):\n",
    "    lengths = {}\n",
    "    tv = 1\n",
    "    cnt = 0\n",
    "    constellation0 = hof[0]\n",
    "    constellation1 = hof[1]\n",
    "    subset = list(sub_MODEL_PARAMS.keys())\n",
    "    tg = target.dtc_to_gene(subset_params=subset)\n",
    "    if len(MODEL_PARAMS)==1:\n",
    "        \n",
    "        ax = plt.subplot()\n",
    "        for k,v in MODEL_PARAMS.items():\n",
    "            lengths[k] = np.abs(np.abs(v[1])-np.abs(v[0]))\n",
    "\n",
    "            x = [h[cnt] for h in hof]\n",
    "            y = [0 for h in hof]\n",
    "            ax.set_xlim(v[0],v[1])\n",
    "            ax.set_xlabel(k)\n",
    "            tgene = tg[cnt]\n",
    "            yg = 0\n",
    "\n",
    "        ax.scatter(x, y, c='b', marker='o',label='samples')\n",
    "        ax.scatter(tgene, yg, c='r', marker='*',label='target')\n",
    "        ax.legend()\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    if len(MODEL_PARAMS)==2:\n",
    "        \n",
    "        ax = plt.subplot()\n",
    "        for k,v in MODEL_PARAMS.items():\n",
    "            lengths[k] = np.abs(np.abs(v[1])-np.abs(v[0]))\n",
    "                \n",
    "            if cnt==0:\n",
    "                tgenex = tg[cnt]\n",
    "                x = [h[cnt] for h in hof]\n",
    "                ax.set_xlim(v[0],v[1])\n",
    "                ax.set_xlabel(k)\n",
    "            if cnt==1:\n",
    "                tgeney = tg[cnt]\n",
    "\n",
    "                y = [h[cnt] for h in hof]\n",
    "                ax.set_ylim(v[0],v[1])\n",
    "                ax.set_ylabel(k)\n",
    "            cnt+=1\n",
    "\n",
    "        ax.scatter(x, y, c='r', marker='o',label='samples',s=5)\n",
    "        ax.scatter(tgenex, tgeney, c='b', marker='*',label='target',s=11)\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "    if len(MODEL_PARAMS)==3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for k,v in MODEL_PARAMS.items():\n",
    "            lengths[k] = np.abs(np.abs(v[1])-np.abs(v[0]))\n",
    "        \n",
    "            if cnt==0:\n",
    "                tgenex = tg[cnt]\n",
    "\n",
    "                x = [h[cnt] for h in hof]\n",
    "                ax.set_xlim(v[0],v[1])\n",
    "                ax.set_xlabel(k)\n",
    "            if cnt==1:\n",
    "                tgeney = tg[cnt]\n",
    "\n",
    "                y = [h[cnt] for h in hof]\n",
    "                ax.set_ylim(v[0],v[1])\n",
    "                ax.set_ylabel(k)\n",
    "            if cnt==2:\n",
    "                tgenez = tg[cnt]\n",
    "\n",
    "                z = [h[cnt] for h in hof]\n",
    "                ax.set_zlim(v[0],v[1])\n",
    "                ax.set_zlabel(k)\n",
    "\n",
    "            cnt+=1\n",
    "        ax.scatter(x, y, z, c='r', marker='o')\n",
    "        ax.scatter(tgenex, tgeney,tgenez, c='b', marker='*',label='target',s=21)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "sub_MODEL_PARAMS = copy.copy(MODEL_PARAMS['IZHI'])\n",
    "\n",
    "\n",
    "sub_MODEL_PARAMS\n",
    "hof_to_euclid(hall_of_fame,sub_MODEL_PARAMS,target)\n",
    "sub_MODEL_PARAMS\n",
    "hof_to_euclid(final_pop,sub_MODEL_PARAMS,target)\n",
    "subset = list(sub_MODEL_PARAMS.keys())\n",
    "tg = target.dtc_to_gene(subset_params=subset)\n",
    "tg\n",
    "MODEL_PARAMS['IZHI']\n",
    "tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for gene in list(hist.genealogy_history.values()):\n",
    "hof_to_euclid(list(hist.genealogy_history.values()),sub_MODEL_PARAMS,target)\n",
    "sub_MODEL_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import basic_expVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "opt = dtc_to_rheo(opt)\n",
    "print(opt.rheobase)\n",
    "print(target.rheobase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_binary_match(opt,target,plotly=False,snippets=False)\n",
    "check_binary_match(opt,target,plotly=False,snippets=True)\n",
    "print(basic_expVar(target.vmrh, opt.vmrh), 'variancce explained ratio at rheobase')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['injected_square_current'] = {}\n",
    "#if v.name in str('RestingPotentialTest'):\n",
    "params['injected_square_current']['delay'] = PASSIVE_DELAY\n",
    "params['injected_square_current']['duration'] = PASSIVE_DURATION\n",
    "params['injected_square_current']['amplitude'] = 0.0*pq.pA    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt_model = opt.dtc_to_model()\n",
    "opt_model.inject_square_current(params)\n",
    "opt_vm = opt_model.get_membrane_potential()\n",
    "opt_vm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = target.dtc_to_model()\n",
    "target_model.inject_square_current(params)\n",
    "target_vm = target_model.get_membrane_potential()\n",
    "target_vm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ind = hall_of_fame[1]\n",
    "#print('Best individual: ', best_ind)\n",
    "#print('Fitness values: ', best_ind.fitness.values)\n",
    "\n",
    "\n",
    "# We can evaluate this individual and make use of a convenience function of the cell evaluator to return us a dict of the parameters\n",
    "\n",
    "\n",
    "best_ind_dict = cell_evaluator.param_dict(best_ind)\n",
    "#print(cell_evaluator.evaluate_with_dicts(best_ind_dict))\n",
    "\n",
    "\n",
    "model = cell_evaluator.cell_model\n",
    "dtc= model.model_to_dtc()\n",
    "opt = dtc_to_rheo(opt)\n",
    "print(opt.rheobase)\n",
    "print(target.rheobase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.rheobase\n",
    "objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "best_ind_dict = cell_evaluator.param_dict(best_ind)\n",
    "objectives = cell_evaluator.evaluate_with_dicts(best_ind_dict)\n",
    "\n",
    "objectives2 = cell_evaluator2.evaluate_with_dicts(best_ind_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "logbook = logs\n",
    "#scores = [ m for m in logs ]\n",
    "'''\n",
    "list_of_dicts = []\n",
    "df1 = pd.DataFrame()\n",
    "genes=[]\n",
    "for _,v in hist.genealogy_history.items():\n",
    "    genes.append(v.fitness.values)\n",
    "for j,i in enumerate(objectives.keys()):\n",
    "    index = i.split('.')[0]\n",
    "    df1[str(index)] = pd.Series(genes).values[j]#, index=df1.index)\n",
    "\n",
    "'''\n",
    "#MU =14\n",
    "genes=[]\n",
    "min_per_generations = []\n",
    "for i,v in hist.genealogy_history.items():\n",
    "    if i%MU==0:\n",
    "        min_per_gen = sorted([(gene,np.min(gene)) for gene in genes],key=lambda x: x[1])\n",
    "        min_per_generations.append(min_per_gen[0][0])\n",
    "        genes =[]\n",
    "    genes.append(v.fitness.values)\n",
    "    \n",
    "df2 = pd.DataFrame()\n",
    "scores = []\n",
    "for j,i in enumerate(objectives.keys()):\n",
    "    index = i.split('.')[0]\n",
    "    print([i[j] for i in min_per_generations ])\n",
    "    df2[index] = pd.Series([i[j] for i in min_per_generations ])#, index=df1.index)\n",
    "df2    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=int(np.sqrt(len(df2.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "box = int(np.sqrt(len(objectives)))\n",
    "fig,axes = plt.subplots(box,box+1,figsize=(20,20))#math.ceil(len(objectives)/2+1),figsize=(20,20))\n",
    "#axes[0,0].plot(scores)\n",
    "#axes[0,0].plot(gen_numbers, min_fitness, label='min fitness')\n",
    "\n",
    "axes[0,0].set_title('Observation/Prediction Disagreement')\n",
    "for i,c in enumerate(df2.columns):\n",
    "    ax = axes.flat[i+1]\n",
    "    history = df2[c]\n",
    "    #mn = mean[k.name] \n",
    "    #st = std[k.name] \n",
    "    #history = [(j[i]-mn)/st for j in scores ]\n",
    "    #ax.axhline(y=mn , xmin=0.02, xmax=0.99,color='red',label='best candidate sampled')\n",
    "\n",
    "    #ax.axvline(x=min_x , ymin=0.02, ymax=0.99,color='blue',label='best candidate sampled')\n",
    "    ax.plot(history)\n",
    "    ax.set_title(str(c))\n",
    "    #bigger = np.max([np.max(history),mn])\n",
    "    #smaller = np.max([np.min(history),mn])\n",
    "\n",
    "    #ax.set_ylim([np.min(history),np.max(history)])\n",
    "    #ax.set_ylabel(str(front[0].dtc.tests[i].observation['std'].units))\n",
    "axes[0,0].set_xlabel(\"Generation\")\n",
    "axes[0,0].set_ylabel(\"standardized error\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#if figname is not None:\n",
    "#    plt.savefig(figname)\n",
    "#else:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logbook = logs\n",
    "#scores = [ m for m in logs ]\n",
    "list_of_dicts = []\n",
    "df1 = pd.DataFrame()\n",
    "genes=[]\n",
    "for _,v in hist.genealogy_history.items():\n",
    "    genes.append(v.fitness.values)\n",
    "for j,i in enumerate(objectives2.keys()):\n",
    "    index = i.split('.')[0]\n",
    "    df1[str(index)] = pd.Series(genes).values[j]#, index=df1.index)\n",
    "\n",
    "\n",
    "    \n",
    "#if normalize:\n",
    "#    a = (a - mean(a)) / (std(a) * len(a))\n",
    "#    v = (v - mean(v)) /  std(v)\n",
    "\n",
    "df1=(df1-df1.mean())/df1.std()\n",
    "\n",
    "corr = df1.corr()#.normalize()\n",
    "fig =plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)#, annot=True)\n",
    "plt.show()\n",
    "print(np.sum(np.sum(corr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "logbook = logs\n",
    "list_of_dicts = []\n",
    "df1 = pd.DataFrame()\n",
    "genes=[]\n",
    "for _,v in hist.genealogy_history.items():\n",
    "    genes.append(v.fitness.values)\n",
    "for j,i in enumerate(objectives2.keys()):\n",
    "    index = i.split('.')[0]\n",
    "    df1[str(index)] = pd.Series(genes).values[j]#, index=df1.index)\n",
    "\n",
    "\n",
    "    \n",
    "#if normalize:\n",
    "#    a = (a - mean(a)) / (std(a) * len(a))\n",
    "#    v = (v - mean(v)) /  std(v)\n",
    "\n",
    "df1=(df1-df1.mean())/df1.std()\n",
    "\n",
    "corr = df1.corr()#.normalize()\n",
    "fig =plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)#, annot=True)\n",
    "plt.show()\n",
    "print(np.sum(np.sum(corr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.genealogy_history.keys();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.genealogy_tree.keys();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "graph = networkx.DiGraph(hist.genealogy_tree)\n",
    "graph = graph.reverse()     # Make the graph top-down\n",
    "per_generation = [(gen,hist.genealogy_history[gen].fitness.values) for gen in graph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp['halloffame'][-1].fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp['halloffame'][0].fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp['population'][-1].fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pop \n",
    "hall_of_fame[-1].fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hall_of_fame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(hall_of_fame),0,-1)],[np.sum(i.fitness.values) for i in hall_of_fame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(0,len(hall_of_fame))],[np.sum(hall_of_fame[i].fitness.values) for i in range(len(hall_of_fame)-1,-1,-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "genes=[]\n",
    "\n",
    "for v in hall_of_fame:\n",
    "    #v = hall_of_fame[j]\n",
    "    genes.append(v.fitness.values)\n",
    "\n",
    "#for i in \n",
    "#    plt.plot([i for i in range(0,len(hall_of_fame))],[hall_of_fame[i].fitness.values[j] for i in range(len(hall_of_fame)-1,-1,-1)])\n",
    "#    plt.show()\n",
    "df1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,i in enumerate(objectives.keys()):\n",
    "    index = i.split('.')[0]\n",
    "    df1[str(index)] = pd.Series(genes).values[j]#, index=df1.index)\n",
    "\n",
    "df1=(df1-df1.mean())/df1.std()\n",
    "\n",
    "corr = df1.corr()\n",
    "fig =plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)#, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for j,i in enumerate(objectives2.keys()):\n",
    "    index = i.split('.')[0]\n",
    "    df1[str(index)] = pd.Series(genes).values[j]#, index=df1.index)\n",
    "\n",
    "df1=(df1-df1.mean())/df1.std()\n",
    "\n",
    "corr = df1.corr()\n",
    "fig =plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)#, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
=======
>>>>>>> 40ee74c6df1e7a853f8c448ea6000eb4acdf0935
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a7c192c0b3f4970961a62f852a0f0d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "131df462cdcf49a283732a5e65fde7d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "188947e99433493f86277514d537642c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2feae04b870d4271b367a3cfe08d448b",
        "IPY_MODEL_275d17ff05bb493aa2f357a52179cdd4"
       ],
       "layout": "IPY_MODEL_0a7c192c0b3f4970961a62f852a0f0d7"
      }
     },
     "275d17ff05bb493aa2f357a52179cdd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7fe050341feb471ea01b0a6ce50b32c0",
       "style": "IPY_MODEL_9b145f7655e649f092b94e847b8d8665",
       "value": " 100/100 [09:31&lt;00:00,  5.71s/it]"
      }
     },
     "2feae04b870d4271b367a3cfe08d448b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_131df462cdcf49a283732a5e65fde7d8",
       "style": "IPY_MODEL_ac77f4ea25c14ca3b85e0b37a3104e37",
       "value": 100
      }
     },
     "7fe050341feb471ea01b0a6ce50b32c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9b145f7655e649f092b94e847b8d8665": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ac77f4ea25c14ca3b85e0b37a3104e37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
